{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resolution search with ENOT\n",
    "\n",
    "This notebook describes the basic steps you need to optimize an architecture with fixed latency and search best input resolution using ENOT framework.\n",
    "\n",
    "### Main chapters of this notebook:\n",
    "1. Setup the environment\n",
    "1. Prepare dataset and create dataloaders\n",
    "1. Create model and move it into search space\n",
    "1. Pretrain constructed search space on different resolutions\n",
    "1. Search best architecture and resolution\n",
    "1. Tune model with the best architecture on the best resolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup the environment\n",
    "First, let's set up the environment and make some common imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'\n",
    "# You may need to change this variable to match free GPU index\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.optim import Adam\n",
    "from torch.optim import SGD\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch_optimizer import RAdam\n",
    "\n",
    "from enot.models import SearchSpaceModel\n",
    "from enot.models.mobilenet import build_mobilenet\n",
    "from enot.optimize import EnotPretrainOptimizer\n",
    "from enot.optimize import EnotSearchOptimizer\n",
    "from enot.latency import best_arch_latency\n",
    "\n",
    "from enot.experimental.resolution_search import ConstantResolutionStrategy\n",
    "from enot.experimental.resolution_search import PretrainResolutionStrategy\n",
    "from enot.experimental.resolution_search import SearchResolutionWithFixedLatencyIterator\n",
    "\n",
    "from tutorial_utils.train_utils import accuracy\n",
    "from tutorial_utils.train_utils import WarmupScheduler\n",
    "\n",
    "from tutorial_utils.checkpoints import download_resolution_search_pretrain_checkpoint\n",
    "from tutorial_utils.dataset import create_imagenette_dataloaders\n",
    "\n",
    "from tutorial_utils.phases import tutorial_pretrain_loop\n",
    "from tutorial_utils.phases import tutorial_search_loop\n",
    "from tutorial_utils.phases import tutorial_train_loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In the following cell we setup all necessary dirs\n",
    "\n",
    "* `ENOT_HOME_DIR` - ENOT framework home directory\n",
    "* `ENOT_DATASETS_DIR` - root directory for datasets (imagenette2, ...)\n",
    "* `PROJECT_DIR` - project directory to save training logs, checkpoints, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENOT_HOME_DIR = Path.home() / '.enot'\n",
    "ENOT_DATASETS_DIR = ENOT_HOME_DIR / 'datasets'\n",
    "PROJECT_DIR = ENOT_HOME_DIR / 'classification_resolution_search'\n",
    "\n",
    "ENOT_HOME_DIR.mkdir(exist_ok=True)\n",
    "ENOT_DATASETS_DIR.mkdir(exist_ok=True)\n",
    "PROJECT_DIR.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare dataset and create dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = create_imagenette_dataloaders(\n",
    "    dataset_root_dir=ENOT_DATASETS_DIR, \n",
    "    project_dir=PROJECT_DIR,\n",
    "    input_size=(224, 224),\n",
    "    batch_size=32,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create model and move it into search space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search space will have these ops as choose options in each layer.\n",
    "# Short format for operations is 'Name_param1=value1_param2=value2...'.\n",
    "# MIB is a MNv2 inverted bottleneck, k is a kernel size for depthwise\n",
    "# convolution, and t is an expansion ratio coefficient.\n",
    "# See more in-depth info in \"Tutorial - adding custom operations\".\n",
    "SEARCH_OPS = [\n",
    "    'MIB_k=3_t=6',\n",
    "    'MIB_k=5_t=6',\n",
    "    'MIB_k=7_t=6',\n",
    "    'conv1x1-skip',\n",
    "]\n",
    "\n",
    "# build model\n",
    "model = build_mobilenet(\n",
    "    search_ops=SEARCH_OPS,\n",
    "    num_classes=10,\n",
    "    blocks_out_channels=[24, 32, 64, 96, 160, 320],\n",
    "    blocks_count=[2, 2, 2, 1, 2, 1],\n",
    "    blocks_stride=[2, 2, 2, 1, 2, 1],\n",
    ")\n",
    "\n",
    "# move model to search space\n",
    "search_space = SearchSpaceModel(model).cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretrain constructed search space\n",
    "Pretrain phase in case of resolution search is simalar to regular pretrain procedure. Detailed description of regular\n",
    "pretrain you can find in 'Tutorial - getting started'.\n",
    "\n",
    "Extra steps for resolution search:\n",
    "1. You must create `PretrainResolutionStrategy` object.\n",
    "1. You must use dataloader iterator generated by PretrainResolutionStrategy object.\n",
    "\n",
    "**IMPORTANT: `PretrainResolutionStrategy.__call__(...)` returns iterator, so you must apply strategy on every epoch using train_loader and validation_loader as parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "N_EPOCHS = 3\n",
    "N_WARMUP_EPOCHS = 1\n",
    "\n",
    "# create PretrainResolutionStrategy for resolution range [min_resolution, max_resolution]\n",
    "pretrain_resolution_strategy = PretrainResolutionStrategy(\n",
    "    min_resolution=100,\n",
    "    max_resolution=300,\n",
    ")\n",
    "\n",
    "train_loader = dataloaders['pretrain_train_dataloader']\n",
    "validation_loader = dataloaders['pretrain_validation_dataloader']\n",
    "\n",
    "metric_function = accuracy\n",
    "loss_function = nn.CrossEntropyLoss().cuda()\n",
    "\n",
    "# using `search_space.model_parameters()` as optimizable variables\n",
    "optimizer = SGD(params=search_space.model_parameters(), lr=0.06, momentum=0.9, weight_decay=1e-4)\n",
    "enot_optimizer = EnotPretrainOptimizer(search_space=search_space, optimizer=optimizer)\n",
    "\n",
    "len_train_loader = len(train_loader)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=len_train_loader*N_EPOCHS, eta_min=1e-8)\n",
    "scheduler = WarmupScheduler(scheduler, warmup_steps=len_train_loader*N_WARMUP_EPOCHS)\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    print(f'EPOCH #{epoch}')\n",
    "\n",
    "    search_space.train()\n",
    "    train_metrics_acc = {\n",
    "        'loss': 0.0,\n",
    "        'accuracy': 0.0,\n",
    "        'n': 0,\n",
    "    }\n",
    "    # apply resolution strategy and start iteration \n",
    "    for inputs, labels in pretrain_resolution_strategy(train_loader):\n",
    "        if not search_space.output_distribution_optimization_enabled:\n",
    "            search_space.initialize_output_distribution_optimization(inputs)\n",
    "\n",
    "        enot_optimizer.zero_grad()\n",
    "\n",
    "        def closure():\n",
    "            pred_labels = search_space(inputs)\n",
    "            batch_loss = loss_function(pred_labels, labels)\n",
    "            batch_loss.backward()\n",
    "            batch_metric = metric_function(pred_labels, labels)\n",
    "\n",
    "            train_metrics_acc['loss'] += batch_loss.item()\n",
    "            train_metrics_acc['accuracy'] += batch_metric.item()\n",
    "            train_metrics_acc['n'] += 1\n",
    "\n",
    "        enot_optimizer.step(closure)\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "\n",
    "    train_loss = train_metrics_acc['loss'] / train_metrics_acc['n']\n",
    "    train_accuracy = train_metrics_acc['accuracy'] / train_metrics_acc['n']\n",
    "\n",
    "    print('train metrics:')\n",
    "    print('  loss:', train_loss)\n",
    "    print('  accuracy:', train_accuracy)\n",
    "\n",
    "    search_space.eval()\n",
    "    validation_loss = 0\n",
    "    validation_accuracy = 0\n",
    "    # apply resolution strategy and start iteration \n",
    "    for inputs, labels in pretrain_resolution_strategy(validation_loader):\n",
    "        search_space.sample_random_arch()\n",
    "\n",
    "        pred_labels = search_space(inputs)\n",
    "        batch_loss = loss_function(pred_labels, labels)\n",
    "        batch_metric = metric_function(pred_labels, labels)\n",
    "\n",
    "        validation_loss += batch_loss.item()\n",
    "        validation_accuracy += batch_metric.item()\n",
    "\n",
    "    n = len(validation_loader)\n",
    "    validation_loss /= n\n",
    "    validation_accuracy /= n\n",
    "\n",
    "    print('validation metrics:')\n",
    "    print('  loss:', validation_loss)\n",
    "    print('  accuracy:', validation_accuracy)\n",
    "\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We pretrained search space for 3 epochs in this example. In this cell, we are downloading\n",
    "# search space checkpoint, pretrained for 100 epochs (for demonstration purposes).\n",
    "\n",
    "checkpoint_path = PROJECT_DIR / 'resolution_search_pretrain_checkpoint.pth'\n",
    "download_resolution_search_pretrain_checkpoint(checkpoint_path)\n",
    "\n",
    "search_space.load_state_dict(\n",
    "    torch.load(checkpoint_path)['model'],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search best architecture and resolution\n",
    "Search phase in case of resolution search is simular to regular pretrain procedure. Detailed description of regular\n",
    "search you can find in 'Tutorial - getting started'.\n",
    "\n",
    "Extra steps for resolution search:\n",
    "1. You must create `SearchResolutionWithFixedLatencyIterator` iterator object for fixed resolution range and fixed target latency.\n",
    "1. On Every iteration `SearchResolutionWithFixedLatencyIterator`:\n",
    "    1. Reset search space state and initialize latency for current resolution\n",
    "    1. Reset optimizer state\n",
    "    1. Returns `SearchResolutionStepData` object, which contains enot_optimizer, latency_loss_weight, resolution_strategy, metric_latency_cb for current search step\n",
    "1. You must follow regular search phase steps using parameters returned by `SearchResolutionWithFixedLatencyIterator` object     \n",
    "1. Before the next iteration you must send final values of validation accuracy and latency of the best architecture using `metric_latency_cb`\n",
    "\n",
    "**IMPORTANT: `resolution_strategy.__call__(...)` returns iterator, so you must apply strategy on every epoch using train_loader and validation_loader as parameters**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "N_EPOCHS = 5\n",
    "\n",
    "metric_function = accuracy\n",
    "loss_function = nn.CrossEntropyLoss().cuda()\n",
    "\n",
    "train_loader = dataloaders['search_train_dataloader']\n",
    "validation_loader = dataloaders['search_validation_dataloader']\n",
    "\n",
    "optimizer = RAdam(search_space.architecture_parameters(), lr=0.01)\n",
    "\n",
    "# create SearchResolutionWithFixedLatencyIterator iterator object \n",
    "# for fixed resolution range and fixed target latency\n",
    "search_resolution_iter = SearchResolutionWithFixedLatencyIterator(\n",
    "    search_space=search_space,\n",
    "    optimizer=optimizer,\n",
    "    data_loader=train_loader,\n",
    "    target_latency=250.0,\n",
    "    latency_tol=5.0,\n",
    "    latency_type='mmac',\n",
    "    min_resolution=100,\n",
    "    max_resolution=300,\n",
    "    resolution_tol=32,\n",
    "    max_latency_loss_weight=0.01,\n",
    ")\n",
    "\n",
    "for r_step, search_step_data in enumerate(search_resolution_iter):\n",
    "    print(f'RESOLUTION_SEARCH_STEP #{r_step}')\n",
    "    validation_accuracy, latency = None, None\n",
    "    for epoch in range(N_EPOCHS):\n",
    "        print(f'EPOCH #{epoch}')\n",
    "\n",
    "        search_space.train()\n",
    "        train_metrics_acc = {\n",
    "            'loss': 0.0,\n",
    "            'accuracy': 0.0,\n",
    "            'n': 0,\n",
    "        }\n",
    "        # apply resolution strategy and start iteration \n",
    "        for inputs, labels in search_step_data.resolution_strategy(train_loader):\n",
    "            search_step_data.enot_optimizer.zero_grad()\n",
    "\n",
    "            def closure():\n",
    "                pred_labels = search_space(inputs)\n",
    "                batch_loss = loss_function(pred_labels, labels)\n",
    "                batch_loss += search_space.loss_latency_expectation * search_step_data.latency_loss_weight\n",
    "\n",
    "                batch_loss.backward()\n",
    "                batch_metric = metric_function(pred_labels, labels)\n",
    "\n",
    "                train_metrics_acc['loss'] += batch_loss.item()\n",
    "                train_metrics_acc['accuracy'] += batch_metric.item()\n",
    "                train_metrics_acc['n'] += 1\n",
    "\n",
    "            search_step_data.enot_optimizer.step(closure)\n",
    "\n",
    "        train_loss = train_metrics_acc['loss'] / train_metrics_acc['n']\n",
    "        train_accuracy = train_metrics_acc['accuracy'] / train_metrics_acc['n']\n",
    "\n",
    "        search_space.eval()\n",
    "        # selecting best architecture for validation\n",
    "        search_space.sample_best_arch()\n",
    "\n",
    "        validation_loss = 0\n",
    "        validation_accuracy = 0\n",
    "        # apply resolution strategy and start iteration \n",
    "        for inputs, labels in search_step_data.resolution_strategy(validation_loader):\n",
    "            pred_labels = search_space(inputs)\n",
    "            batch_loss = loss_function(pred_labels, labels)\n",
    "            batch_metric = metric_function(pred_labels, labels)\n",
    "\n",
    "            validation_loss += batch_loss.item()\n",
    "            validation_accuracy += batch_metric.item()\n",
    "\n",
    "        n = len(validation_loader)\n",
    "        validation_loss /= n\n",
    "        validation_accuracy /= n\n",
    "\n",
    "        # getting latency of the best architecture\n",
    "        latency = best_arch_latency(search_space)\n",
    "\n",
    "    print('train accuracy:', train_accuracy)\n",
    "    print('train loss:', train_loss)\n",
    "    print('validation accuracy:', validation_accuracy)\n",
    "    print('validation loss:', validation_loss)\n",
    "    print('latency:', latency)\n",
    "    print()\n",
    "    \n",
    "    # send final values of validation accuracy and latency of the best architecture\n",
    "    search_step_data.metric_latency_cb(\n",
    "        metric=validation_accuracy, \n",
    "        latency=latency,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_resolution_iter.load_best_arch_parameters(search_space)\n",
    "best_resolution = search_resolution_iter.best_resolution\n",
    "\n",
    "print(f'Best resolution is {best_resolution}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tune model with the best architecture\n",
    "Now we take our best architecture from search space, and create a regular model using it. Then we run finetune procedure (usual training loop)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get regular model with the best architecture\n",
    "best_model = search_space.get_network_with_best_arch().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "N_EPOCHS = 1\n",
    "\n",
    "optimizer = SGD(best_model.parameters(), lr=2e-4)\n",
    "scheduler = None\n",
    "metric_function = accuracy\n",
    "loss_function = nn.CrossEntropyLoss().cuda()\n",
    "\n",
    "train_loader = dataloaders['tune_train_dataloader']\n",
    "validation_loader = dataloaders['tune_validation_dataloader']\n",
    "\n",
    "# You can use ConstantResolutionStrategy for reproducing data processing pipeline from resolution search.\n",
    "to_best_resolution = ConstantResolutionStrategy(\n",
    "    resolution=best_resolution,\n",
    ")\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "\n",
    "    print(f'EPOCH #{epoch}')\n",
    "\n",
    "    best_model.train()\n",
    "    train_loss = 0.0\n",
    "    train_accuracy = 0.0\n",
    "    for inputs, labels in to_best_resolution(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "            \n",
    "        pred_labels = best_model(inputs)\n",
    "        batch_loss = loss_function(pred_labels, labels)\n",
    "        batch_loss.backward()\n",
    "        batch_metric = metric_function(pred_labels, labels)\n",
    "            \n",
    "        train_loss += batch_loss.item()\n",
    "        train_accuracy += batch_metric.item()\n",
    "\n",
    "        optimizer.step()\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "\n",
    "    n = len(train_loader)\n",
    "    train_loss /= n\n",
    "    train_accuracy /= n\n",
    "\n",
    "    print('train metrics:')\n",
    "    print('  loss:', train_loss)\n",
    "    print('  accuracy:', train_accuracy)\n",
    "    \n",
    "    best_model.eval()    \n",
    "    validation_loss = 0\n",
    "    validation_accuracy = 0\n",
    "    for inputs, labels in to_best_resolution(validation_loader):\n",
    "        pred_labels = best_model(inputs)\n",
    "        batch_loss = loss_function(pred_labels, labels)\n",
    "        batch_metric = metric_function(pred_labels, labels)\n",
    "\n",
    "        validation_loss += batch_loss.item()\n",
    "        validation_accuracy += batch_metric.item()\n",
    "    \n",
    "    n = len(validation_loader)\n",
    "    validation_loss /= n\n",
    "    validation_accuracy /= n\n",
    "    \n",
    "    print('validation metrics:')\n",
    "    print('  loss:', validation_loss)\n",
    "    print('  accuracy:', validation_accuracy)\n",
    "    \n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
