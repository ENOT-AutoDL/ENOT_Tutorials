{"nbformat":4,"nbformat_minor":4,"metadata":{"kernelspec":{"name":"python3","display_name":"Yandex DataSphere Kernel","language":"python"},"language_info":{"file_extension":".py","version":"3.7.7","mimetype":"text/x-python","codemirror_mode":{"version":3,"name":"ipython"},"name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3"},"notebookId":"01b15ab4-975c-44dc-b7d6-4f6a821a5e24"},"cells":[{"cell_type":"markdown","source":"## Getting started with ENOT\n\nThis notebook describes the basic steps you need to optimize an architecture.\n\n### Notebook consists of next main stages:\n1. Setup the environment\n1. Prepare dataset and create dataloaders\n1. Create the model and move it to search space\n1. Pretrain constructed search space\n1. Search best architecture\n1. Tune model with best architecture","metadata":{"cellId":"hfa8hepxbumm87h98h2e"}},{"cell_type":"markdown","source":"## 1. Setup the environment\nFirst, let's set up the environment and common imports.","metadata":{"cellId":"h54gzttoh3opj3t61szfgs"}},{"cell_type":"code","source":"import sys\n\nsys.path.append('ENOT_Tutorials')","metadata":{"cellId":"nnriq5r9mlaec19eamggeu"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from pathlib import Path\n\nimport torch\nimport torch.nn as nn\n\nfrom torch.optim import SGD\nfrom torch.optim.lr_scheduler import CosineAnnealingLR\nfrom torch_optimizer import RAdam\n\nfrom enot.models import SearchSpaceModel\nfrom enot.models.mobilenet import build_mobilenet\nfrom enot.phases import pretrain\nfrom enot.phases import search\nfrom enot.phases import train\n\nfrom enot_utils.metric_utils import accuracy\nfrom enot_utils.schedulers import WarmupScheduler\n\nfrom tutorial_utils.checkpoints import download_getting_started_pretrain_checkpoint\nfrom tutorial_utils.dataset import create_imagenette_dataloaders","metadata":{"cellId":"thsyhpf2gilb1hu1cngeo"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### In the next cell we setup all required dirs\n\n* `ENOT_HOME_DIR` - is root dir for all other dirs\n* `ENOT_DATASETS_DIR` - is root dir for datasets (imagenette2)\n* `PROJECT_DIR` - is root dir for output data (checkpoints, logs...) of current tutorial","metadata":{"cellId":"jaz486tqygbdtw4hb17v4i"}},{"cell_type":"code","source":"ENOT_HOME_DIR = Path.home() / '.enot'\nENOT_DATASETS_DIR = ENOT_HOME_DIR / 'datasets'\nPROJECT_DIR = ENOT_HOME_DIR / 'getting_started'\n\nENOT_HOME_DIR.mkdir(exist_ok=True)\nENOT_DATASETS_DIR.mkdir(exist_ok=True)\nPROJECT_DIR.mkdir(exist_ok=True)","metadata":{"cellId":"6nl15rx1leqjjxa3mzak1q"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 2. Prepare dataset and create dataloaders\n\nIn this example we will use dataset Imagenette2. <br>\n`create_imagenette_dataloaders` function do all dirty work: \n1. automatically downloads and unpack dataset in `ENOT_DATASETS_DIR`\n1. split dataset on 4 parts and save annotation of every part in `PROJECT_DIR`:\n    * train - for pretrain and tuning stages (`PROJECT_DIR`/train.csv)\n    * validation - to choose checkpoint for architecture optimization (`PROJECT_DIR`/validation.csv)\n    * search - for architecture optimization stage (`PROJECT_DIR`/search.csv)\n    * test - held-out data for testing (`PROJECT_DIR`/test.csv)\n1. create dataloaders for every stage and returns dataloaders as dictionary:\n    * pretrain_train_dataloader - pretrain train dataloader (based on `PROJECT_DIR`/train.csv)\n    * pretrain_validation_dataloader - pretrain validation dataloader (based on `PROJECT_DIR`/validation.csv)\n    * search_train_dataloader - search train dataloader (based on `PROJECT_DIR`/search.csv)\n    * search_validation_dataloader - search validation dataloader (based on `PROJECT_DIR`/search.csv)\n    * tune_train_dataloader - tune train dataloader (the same as pretrain_train_dataloader)\n    * tune_validation_dataloader - tune validation dataloader (the same as pretrain_validation_dataloader)\n\n**NOTE:**<br>\nCSV annotations follow this format:\n```\nfilepath,label\n<relative_path_1>,<int_label_1>\n<relative_path_2>,<int_label_2>\n...\n```","metadata":{"cellId":"un59ljnrep9yb7dau4qnu"}},{"cell_type":"code","source":"dataloaders = create_imagenette_dataloaders(\n    dataset_root_dir=ENOT_DATASETS_DIR, \n    project_dir=PROJECT_DIR,\n    input_size=(224, 224),\n    batch_size=32,\n)","metadata":{"cellId":"ufmxdngxoboutlszvfv65e"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 3. Create the model and move it to search space\n\nOur architecture optimization procedure selects the best combination of operations from a user-defined search space. The easiest way to define one is to take a base architecture and add similar operations with different parameters: kernel size, expansion ratio, etc. You can also add different kinds of operations or implement your own (see \"Tutorial - adding a custom operation\" for this).\n\nIn this example we take MobileNet v2 as a base architecture and make a search space from MobileNet inverted bottleneck blocks.\n\nFirst, let's define a model for image classification tasks. MobileNet like models can be built by `build_mobilenet` function. `build_mobilenet` function returns model with the following structure: (inputs) -> stem -> blocks -> head -> (outputs). Stem and head have a fixed structure, blocks consist of user-defined operations to choose from at the search stage. The template class will follow MobileNet v2 structure, [as seen in torchvision](https://github.com/pytorch/vision/blob/master/torchvision/models/mobilenet.py).","metadata":{"cellId":"5gq2dwxp47p0r1zxwy3xm8"}},{"cell_type":"code","source":"# The search space will have these ops to choose from in each layer\n# Short format for operations is 'Name_param1=value1_param2=value2...'\n# MIB is MNv2 inverted bottleneck. k is kernel size, t is expansion ratio\n# See more in-depth info in \"Tutorial - adding custom operations\"\nSEARCH_OPS = [\n    'MIB_k=3_t=6',\n    'MIB_k=5_t=6',\n    'MIB_k=7_t=6',\n]\n\n# build model\nmodel = build_mobilenet(\n    search_ops=SEARCH_OPS,\n    num_classes=10,\n    blocks_out_channels=[24, 32, 64, 96, 160, 320],\n    blocks_count=[2, 2, 2, 1, 2, 1],\n    blocks_stride=[2, 2, 2, 1, 2, 1],\n)\n# move model to search space\nsearch_space = SearchSpaceModel(model).cuda()","metadata":{"cellId":"gno580t61tqv4upbgy4bm"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 4. Pretrain constructed search space\n\nWe've implemented a default training procedure for you. You only need to set up search space, data loaders, transforms, and optimizer and run it.\n\n**IMPORTANT:**<br>\n`N_EPOCHS` should be in range >= 300, if you wanna get good pretrain. In this tutorial we set `N_EPOCHS` = 3 and download checkpoint of trained model from Google Drive. ","metadata":{"cellId":"rxyujctdahibh7nv2gwuev"}},{"cell_type":"code","source":"# define directory for text logs and tensorboard logs\npretrain_dir = PROJECT_DIR / 'pretrain'\npretrain_dir.mkdir(exist_ok=True)\n\nN_EPOCHS = 3\nN_WARMUP_EPOCHS = 1\nlen_train = len(dataloaders['pretrain_train_dataloader'])\n\noptimizer = SGD(params=search_space.model_parameters(), lr=0.06, momentum=0.9, weight_decay=1e-4)\nscheduler = CosineAnnealingLR(optimizer, T_max=len_train*N_EPOCHS, eta_min=1e-8)\nscheduler = WarmupScheduler(scheduler, warmup_steps=len_train*N_WARMUP_EPOCHS)\nloss_function = nn.CrossEntropyLoss().cuda()\n\npretrain(\n    search_space=search_space,\n    exp_dir=pretrain_dir,\n    train_loader=dataloaders['pretrain_train_dataloader'],\n    valid_loader=dataloaders['pretrain_validation_dataloader'],\n    optimizer=optimizer,\n    scheduler=scheduler,\n    metric_function=accuracy,\n    loss_function=loss_function,\n    epochs=N_EPOCHS,\n)","metadata":{"scrolled":true,"cellId":"eqm17kyb6yfvthp9odpj9"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# You can find best pretrain checkpoint and load it into your search space.\ncheckpoint_path = pretrain_dir / 'getting_started_pretrain_checkpoint.pth'\ndownload_getting_started_pretrain_checkpoint(checkpoint_path)\n\nsearch_space.load_state_dict(\n    torch.load(checkpoint_path)['model'],\n)","metadata":{"cellId":"wrebchwjy43jimao7jvkk"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 5. Search best architecture\nNow that you have a trained search space you can run the search phase. The setup is similar to pretrain.","metadata":{"cellId":"6has719a4lhqo8kwz0in5p"}},{"cell_type":"code","source":"# define directory for text logs and tensorboard logs\nsearch_dir = PROJECT_DIR / 'search'\nsearch_dir.mkdir(exist_ok=True)\n\noptimizer = RAdam(search_space.architecture_parameters(), lr=0.01)\n\nsearch(\n    search_space=search_space,\n    exp_dir=search_dir,\n    search_loader=dataloaders['search_train_dataloader'],\n    valid_loader=dataloaders['search_validation_dataloader'],\n    optimizer=optimizer,\n    loss_function=loss_function,\n    metric_function=accuracy,\n    latency_loss_weight=2.0e-3,\n    epochs=5,\n)","metadata":{"scrolled":true,"cellId":"2iset71h7fob13n8b90soh"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 6. Tune model with best architecture\nNow we take the best architecture in search space and create a regular model using it, then we run finetune procedure.","metadata":{"cellId":"nwpy4qx9yndzxxdsij1kv"}},{"cell_type":"code","source":"# get regular model with best architecture\nbest_model = search_space.get_network_with_best_arch().cuda()","metadata":{"cellId":"vtcnxq13h07wh4lxzgfd28"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# define directory for text logs and tensorboard logs\ntune_dir = PROJECT_DIR / 'tune'\ntune_dir.mkdir(exist_ok=True)\n\noptimizer = RAdam(best_model.parameters(), lr=5e-3, weight_decay=4e-5)\n\ntrain(\n    model=best_model,\n    exp_dir=tune_dir,\n    train_loader=dataloaders['tune_train_dataloader'],\n    valid_loader=dataloaders['tune_validation_dataloader'],\n    optimizer=optimizer,\n    loss_function=loss_function,\n    metric_function=accuracy,\n    epochs=5,\n)","metadata":{"scrolled":true,"cellId":"2uyriqzj2eyzsz6y0b3u0f"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"cellId":"cyrhmhf7fpcajpu0yg5iqs"},"outputs":[],"execution_count":null}]}