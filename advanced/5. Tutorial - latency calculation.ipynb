{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latency calculation with ENOT\n",
    "\n",
    "This notebook describes how to calculate latency using ENOT framework.\n",
    "\n",
    "### Main chapters of this notebook:\n",
    "1. Initialize latency of search space (`SearchSpaceModel`)\n",
    "1. Calculate latency of arbitrary model/module\n",
    "1. Fill `SearchSpaceModel` with precalculated latency\n",
    "1. Save/Load `SearchSpaceLatencyContainer`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize latency of search space (`SearchSpaceModel`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To initialize latency of `SearchSpaceModel` import `SearchSpaceModel` from `enot.models` and `initialize_latency` function from `enot.latency`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enot.models import SearchSpaceModel\n",
    "from enot.latency import initialize_latency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`initialize_latency` has the following signature:\n",
    "\n",
    "```python\n",
    "def initialize_latency(\n",
    "    latency_type: str,\n",
    "    search_space: SearchSpaceModel,\n",
    "    inputs: Tuple,\n",
    "    keyword_inputs: Optional[Dict[str, Any]] = None,\n",
    ") -> SearchSpaceLatencyContainer\n",
    "```\n",
    "\n",
    "`latency_type (str)` — type of the latency to be initialized in `search_space`.\n",
    "Now ENOT supports only multiply-accumulate (MAC) latency type.\n",
    "For MAC latency initialization use `latency_type='mmac'`.\n",
    "\n",
    "For most modules ENOT has built-in MAC calculator, but for unsupported modules it is possible to use third-party calculators:\n",
    "\n",
    "- to use **PyTorch-OpCounter (thop)** third-party MAC calculator pass `latency_type='mmac.thop'`\n",
    "- to use **PyTorch-estimate-flops (pthflops)** third-party MAC calculator pass `latency_type='mmac.pthflops'`\n",
    "\n",
    "Note: third-party calculators complement built-in calculator, i.e. if built-in calculator knows how to calculate latency of module, then third-party calculator will not be used for this module.\n",
    "\n",
    "`search_space` — `SearchSpaceModel` for latency calculation.\n",
    "\n",
    "        \n",
    "`inputs: Tuple` — `search_space` input.\n",
    "\n",
    "Also *keyword arguments* can be passed.\n",
    "\n",
    "\n",
    "`initialize_latency` returns `SearchSpaceLatencyContainer`, that can be used to calculate statistics or visualization of latency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, let us calculate MAC-latency of search space from <span style=\"color:green;white-space:nowrap\">***1. Tutorial - getting started***</span>:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from enot.models.mobilenet import build_mobilenet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_mobilenet(\n",
    "    search_ops=['MIB_k=3_t=6', 'MIB_k=5_t=6', 'MIB_k=7_t=6'],\n",
    "    num_classes=10,\n",
    "    blocks_out_channels=[24, 32, 64, 96, 160, 320],\n",
    "    blocks_count=[2, 2, 2, 1, 2, 1],\n",
    "    blocks_stride=[2, 2, 2, 1, 2, 1],\n",
    ")\n",
    "search_space = SearchSpaceModel(model).cpu()\n",
    "inputs = torch.ones(1, 3, 244, 224)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now MAC-latency of `search_space` can be initialized in the following way:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "initialize_latency('mmac', search_space, (inputs, ));  # ; suppress output of statistics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or we can enable **PyTorch-OpCounter** third-party calculator and print some statistics:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enot.latency import min_latency\n",
    "from enot.latency import mean_latency\n",
    "from enot.latency import max_latency\n",
    "from enot.latency import median_latency\n",
    "from enot.latency import current_latency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "container = initialize_latency('mmac.thop', search_space, (inputs, ))\n",
    "print(f'Constant latency: {container.constant_latency}\\n'\n",
    "      f'Min latency: {min_latency(container)}\\n'\n",
    "      f'Mean latency: {mean_latency(container)}\\n'\n",
    "      f'Max latency: {max_latency(container)}\\n'\n",
    "      f'Median latency: {median_latency(container)}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Container can be visualized as a heatmap, cast to string or printed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enot.visualization.latency import plot_latency_heatmap\n",
    "plot_latency_heatmap(container, annotate_values=True, figsize=(8, 8));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(container)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get latency of `search_space`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "latency = current_latency(search_space)\n",
    "print(f'Latency: {latency}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To reset latency of `search_space` use `reset_latency` from `enot.latency`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enot.latency import reset_latency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reset_latency(search_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space.latency_type == None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate latency of arbitrary model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate latency of arbitary model/module import `MacCalculatorThop` or `MacCalculatorPthflops` from `enot.latency`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enot.latency import MacCalculatorThop\n",
    "from enot.latency import MacCalculatorPthflops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Latency calculators have only one function with the following signature:\n",
    "\n",
    "```python\n",
    "def calculate(\n",
    "    model: nn.Module,\n",
    "    inputs: Tuple,\n",
    "    ignore_modules: Optional[List[Type[nn.Module]]] = None,\n",
    "    **options\n",
    ") -> float:\n",
    "```\n",
    "\n",
    "So you can pass model, inputs and list of modules that you want to ignore in calculation as well as some additional options.\n",
    "\n",
    "For example (model and inputs from previous example are used):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MacCalculatorThop().calculate(model, inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MacCalculatorPthflops().calculate(model, inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fill SearchSpaceModel with precalculated latency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, there are precalculated constant latency (static part of search space) and latencies of operations as **numpy** array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from enot.latency import SearchSpaceLatencyContainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precalc_constant_latency = 10\n",
    "precalc_operations_latencies = np.array([\n",
    "    [1, 2, 3],\n",
    "    [4, 5, 6],\n",
    "    [7, 8, 9],\n",
    "    [1, 2, 3],\n",
    "    [4, 5, 6],\n",
    "    [7, 8, 9],\n",
    "    [1, 2, 3],\n",
    "    [4, 5, 6],\n",
    "    [7, 8, 9],\n",
    "    [1, 2, 3],\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To initialize `SearchSpaceModel` with these latencies it is necessary to create `SearchSpaceLatencyContainer` and fill it with precalculated latencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "container = SearchSpaceLatencyContainer(\n",
    "    latency_type='mmac',\n",
    "    constant_latency=precalc_constant_latency,\n",
    "    operations_latencies=precalc_operations_latencies.tolist(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, apply this container to `SearchSpaceModel`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space.apply_latency_container(container)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, you can extract latency container from `SearchSpaceModel` and, for example, visualize it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_latency_heatmap(search_space.get_latency_container(), figsize=(8, 8));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save/Load SearchSpaceLatencyContainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To save/load `SearchSpaceLatencyContainer` use `save_to_file`/`load_from_file` methods of `SearchSpaceLatencyContainer`:\n",
    "\n",
    "```python\n",
    "container: SearchSpaceLatencyContainer = ...\n",
    "container.save_to_file('my_container')\n",
    "container.load_from_file('my_container')\n",
    "\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "execution": {
   "timeout": 3000
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
