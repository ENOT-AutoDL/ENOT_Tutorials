{"nbformat":4,"nbformat_minor":4,"metadata":{"kernelspec":{"name":"python3","display_name":"Yandex DataSphere Kernel","language":"python"},"language_info":{"file_extension":".py","version":"3.7.7","mimetype":"text/x-python","codemirror_mode":{"version":3,"name":"ipython"},"name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3"},"pycharm":{"stem_cell":{"cell_type":"raw","metadata":{"collapsed":false},"source":[]}},"notebookId":"53e320cd-c1fc-4d5f-bd5a-d09eccb26246"},"cells":[{"cell_type":"markdown","source":"## Using Arcface head for search best architecture on metric learning task\n\n### Notebook consists of next main stages:\n1. Setup the environment\n1. Define ArcfaceHead class and define MetricLearningModel class\n1. Prepare dataloaders\n1. Create the model and move it to search space\n1. Pretrain search_space\n1. Search best architecture\n1. Tune model with best architecture","metadata":{"cellId":"isrpd8q1gpyig8rtoryo"}},{"cell_type":"markdown","source":"## 1. Setup the environment","metadata":{"cellId":"p7amkln9fbrfeyd0yxqurd"}},{"cell_type":"code","source":"import sys\n\nsys.path.append('ENOT_Tutorials')","metadata":{"cellId":"o5l2sf77tqxzqlf0v83u8"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from pathlib import Path\n\nimport torch\nimport torch.nn as nn\n\nfrom torch.nn import functional as F\n\nfrom torch.optim import SGD\nfrom torch_optimizer import RAdam\n\nfrom torchvision.models.mobilenet import ConvBNReLU\n\nfrom enot.models import build_simple_block_model\nfrom enot.models import SearchSpaceModel\nfrom enot.phases import pretrain\nfrom enot.phases import search\nfrom enot.phases import train\nfrom enot.utils.data.csv_annotation_dataset import CsvAnnotationDataset\nfrom enot.utils.data.dataloaders import create_data_loader\nfrom enot.utils.data.dataloaders import create_data_loader_from_csv_annotation\n\nfrom tutorial_utils.checkpoints import download_metric_learning_arcface_pretrain_checkpoint\nfrom tutorial_utils.checkpoints import download_metric_learning_regular_pretrain_checkpoint\nfrom tutorial_utils.dataset import create_imagenette_annotation\nfrom tutorial_utils.dataset import download_imagenette\nfrom tutorial_utils.dataset import create_imagenette_train_transform\nfrom tutorial_utils.dataset import create_imagenette_validation_transform\n\nfrom enot_utils.metric_utils import accuracy","metadata":{"cellId":"sqitb3nwl8heg23gdzlo2"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 2. Define ArcfaceHead class and define MetricLearningModel class","metadata":{"cellId":"9zp4rltv5g9rdrmp9hcfj"}},{"cell_type":"code","source":"class ArcfaceHead(nn.Linear):\n    def __init__(\n            self,\n            in_channels: int,\n            *,\n            radius=64.0,\n            angle_margin=0.5,\n            embedding_channels=512,\n            num_classes=10,\n    ):\n        super().__init__(embedding_channels, num_classes, bias=False)\n        \n        self.radius = radius\n        self.angle_margin = angle_margin\n        self.num_classes = num_classes\n\n        self.vectorizer = nn.Sequential(\n            ConvBNReLU(\n                in_channels, \n                embedding_channels,\n                1, 1, 1, norm_layer=None,\n            ),\n            nn.AdaptiveAvgPool2d([1, 1]),\n            nn.Flatten(),\n        )\n\n    def forward(self, inputs, labels=None):\n        features = F.normalize(self.vectorizer(inputs), 2, -1)\n\n        weights = F.normalize(self.weight, 2, -1)\n        cosine = F.linear(features, weights)\n\n        if labels is not None:\n            angle = torch.acos(cosine)\n            modified_cos = torch.cos(angle + self.angle_margin)\n\n            one_hot = torch.zeros(cosine.size(), device=cosine.device)\n            one_hot.scatter_(1, labels.view(-1, 1).long(), 1)\n            cosine = cosine * (1 - one_hot) + modified_cos * one_hot\n\n        return cosine * self.radius","metadata":{"cellId":"qr5qive3ctjll0c5m5eyyg"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class MetricLearningModel(nn.Module):\n    def __init__(\n        self,\n        search_ops,\n        embedding_channels=512,\n        num_classes=10,\n        radius=64.0,\n        angle_margin=0.0,\n    ):\n        super().__init__()\n        \n        blocks_in_channels = 32\n        blocks_out_channels = 320\n        \n        self.stem = ConvBNReLU(3, blocks_in_channels, stride=2)\n        self.body = build_simple_block_model(\n            in_channels=blocks_in_channels,\n            search_ops=search_ops,\n            blocks_out_channels=[16, 24, 32, 64, 96, 160, blocks_out_channels],\n            blocks_count=[1, 2, 2, 2, 1, 2, 1],\n            blocks_stride=[1, 2, 2, 2, 1, 2, 1],\n            width_multiplier=1.0,\n            min_channels=8,\n            init_weights_kn=True,\n        )\n        self.head = ArcfaceHead(\n            blocks_out_channels,\n            radius=radius,\n            angle_margin=angle_margin,\n            embedding_channels=embedding_channels,\n            num_classes=num_classes,\n        )\n    \n    def update_angle_margin(self, value):\n        self.head.angle_margin = value\n\n    def forward(self, inputs):\n        labels = None\n        if not isinstance(inputs, torch.Tensor):\n            inputs, labels = inputs\n            \n        x = self.stem(inputs)\n        x = self.body(x)\n        x = self.head(x, labels)\n\n        return x","metadata":{"cellId":"6np4kvjeprxzdocjofu1eq"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 3. Prepare dataloaders\nFor arcface training we need to pass labels to head part of the model, so arcface train `Dataset` must return data in the next format `(image, label), label`.  ","metadata":{"cellId":"6yjpftuglzsbknl5m74u8"}},{"cell_type":"code","source":"ENOT_HOME_DIR = Path.home() / '.enot'\nENOT_DATASETS_DIR = ENOT_HOME_DIR / 'datasets'\nPROJECT_DIR = ENOT_HOME_DIR / 'metric_learning'\n\nENOT_HOME_DIR.mkdir(exist_ok=True)\nENOT_DATASETS_DIR.mkdir(exist_ok=True)\nPROJECT_DIR.mkdir(exist_ok=True)","metadata":{"scrolled":true,"cellId":"6fbke1qj2zjagiczwi9d28"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class ArcfaceTrainCsvAnnotationDataset(CsvAnnotationDataset):\n    def __init__(self, csv_annotation_path, root_dir=None, transform=None):\n        super().__init__(csv_annotation_path, root_dir=root_dir, transform=transform)\n    \n    def __getitem__(self, idx):\n        image, label = super().__getitem__(idx)\n        return (image, label), label\n\n\nnum_workers = 4\ninput_size = (224, 224)\nbatch_size = 32\ndataset_dir = download_imagenette(\n    dataset_root_dir=ENOT_DATASETS_DIR, imagenette_kind='imagenette2-320',\n)\nannotations = create_imagenette_annotation(\n    dataset_dir=dataset_dir, project_dir=PROJECT_DIR, random_seed=42,\n)\ntrain_transform = create_imagenette_train_transform(input_size)\nvalidation_transform = create_imagenette_validation_transform(input_size)\n\npretrain_and_tune_train_dataloader = create_data_loader_from_csv_annotation(\n    csv_annotation_path=annotations['train'],\n    dataset_transform=train_transform,\n    batch_size=batch_size,\n    num_workers=num_workers,\n    shuffle=True,\n)\npretrain_and_tune_arcface_train_dataloader = create_data_loader(\n    dataset=ArcfaceTrainCsvAnnotationDataset(annotations['train'], transform=train_transform),\n    batch_size=batch_size,\n    num_workers=num_workers,\n    shuffle=True,\n    collate_fn=None,\n)\npretrain_and_tune_validation_dataloader = create_data_loader_from_csv_annotation(\n    csv_annotation_path=annotations['validation'],\n    dataset_transform=validation_transform,\n    batch_size=batch_size,\n    shuffle=False,\n)\n\nsearch_train_dataloader = create_data_loader_from_csv_annotation(\n    csv_annotation_path=annotations['search'],\n    dataset_transform=train_transform,\n    batch_size=batch_size,\n    num_workers=num_workers,\n    shuffle=True,\n)\nsearch_validation_dataloader = create_data_loader_from_csv_annotation(\n    csv_annotation_path=annotations['search'],\n    dataset_transform=validation_transform,\n    batch_size=batch_size,\n    num_workers=num_workers,\n    shuffle=False,\n)","metadata":{"cellId":"p5skl9la2mgoyc8sbs6npn"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 4. Create the model and move it to search space","metadata":{"cellId":"4i5sv2xpzjb82pwvum1pim"}},{"cell_type":"code","source":"SEARCH_OPS = [\n    'MIB_k=3_t=3',\n    'MIB_k=3_t=6',\n]\n\n# build model\nmodel = MetricLearningModel(search_ops=SEARCH_OPS, angle_margin=0.1)\n# move model to search space\nsearch_space = SearchSpaceModel(model).cuda()","metadata":{"cellId":"39q73ho33gec3rg9diq0ur"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 5. Pretrain search_space\n\nPretrain procedure stages:\n1. We pretrain regular search_space (use regular train dataloader `pretrain_and_tune_train_dataloader`)\n1. Calculate avg cosine distance to centroid for all classes\n1. We pretrain arcface search_space with angle_margin=0.1 (use arcface train dataloader `pretrain_and_tune_arcface_train_dataloader`, which returns labels)\n1. Calculate avg cosine distance to centroid for all classes\n\n**IMPORTANT:**<br>\nWe cannot start training of arcface search_space from the randomly initialized search_space, because it is not efficient. Arcface pretrain starts from pretrained regular model and just tune it. For fair comparison we use next train procedure:<br>\n```\n1-2-3-4-...-N_EPOCHS-...-N_EPOCHS+N_TUNE_EPOCHS <- Regular model\n               |\n         load checkpoint\n               |\n               1-...N_TUNE_EPOCHS <- Arcface model\n```","metadata":{"cellId":"gbkkwtqkyye6j62ynvyyhh"}},{"cell_type":"code","source":"# helper function, which calculate avg cosine distance to centroid for all classes\ndef calc_avg_cosine_dist_to_centroids(search_space, dataloader, num_classes=10, forward_indices=None):\n    avg_distances = [(0.0, 0) for i in range(num_classes)]\n    \n    # We should fixate architecture of search space. It can be any architecture, but \n    # must be the same for arcface and regular models\n    if forward_indices is None:\n        n = len(search_space.search_variants_containers)\n        forward_indices = [[0] for _ in range(n)]\n\n    search_space.eval(sample=True, forward_indices=forward_indices)\n    \n    radius = search_space.original_model.head.radius\n    for inputs, labels in dataloader:\n        labels = labels.detach().cpu().numpy()\n        current_result = search_space(inputs)\n        current_result = current_result.detach().cpu().numpy()\n        \n        for one_result, one_label in zip(current_result, labels):\n            # get \n            dist, n = avg_distances[one_label]\n            # update\n            current_dist = 1 - one_result[one_label]/radius\n            dist += current_dist\n            n += 1\n            # set updated\n            avg_distances[one_label] = dist, n\n        \n    for i in range(num_classes):\n        dist, n = avg_distances[i]\n        avg_distances[i] = dist/n if n != 0 else 0.0\n\n    return avg_distances","metadata":{"cellId":"bugqzjxjakphd19tzgl2l9"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**IMPORTANT:**<br>\n(N_EPOCHS + N_TUNE_EPOCHS) should be ~(100 + 30), if you wanna get good pretrain. In this tutorial we set (N_EPOCHS + N_TUNE_EPOCHS) = (2 + 1) and download checkpoints of pretreined models from Google Drive.","metadata":{"cellId":"tljk4s0c31ehppcx0hee6o"}},{"cell_type":"code","source":"# define directory for text logs and tensorboard logs\npretrain_regular_dir = PROJECT_DIR / 'pretrain_regular'\npretrain_regular_dir.mkdir(exist_ok=True)\npretrain_arcface_dir = PROJECT_DIR / 'pretrain_arcface'\npretrain_arcface_dir.mkdir(exist_ok=True)\n\nN_EPOCHS = 2\nN_TUNE_EPOCHS = 1\nUSE_CHECKPOINTS_FROM_GOOGLE_DRIVE = True\n\noptimizer = SGD(\n    params=search_space.model_parameters(), \n    lr=0.01, \n    momentum=0.9, \n    weight_decay=1e-4\n)\nloss_function = nn.CrossEntropyLoss().cuda()\n\n# pretrain regular search_space\npretrain(\n    search_space=search_space,\n    exp_dir=pretrain_regular_dir,\n    train_loader=pretrain_and_tune_train_dataloader,\n    valid_loader=pretrain_and_tune_validation_dataloader,\n    optimizer=optimizer,\n    metric_function=accuracy,\n    loss_function=loss_function,\n    epochs=N_EPOCHS + N_TUNE_EPOCHS,\n)\nif USE_CHECKPOINTS_FROM_GOOGLE_DRIVE:\n    # download regular pretrain checkpoint from google drive\n    checkpoint_path = pretrain_regular_dir / 'regular_checkpoint.pth'\n    download_metric_learning_regular_pretrain_checkpoint(checkpoint_path)\n    search_space.load_state_dict(\n        torch.load(checkpoint_path)['model'],\n    )\n# calculate distance between classes for regular model\navg_cosine_dist_to_centroids_reg = calc_avg_cosine_dist_to_centroids(\n    search_space=search_space, \n    dataloader=pretrain_and_tune_validation_dataloader, \n)\n\n# load checkpoint for tune\ncheckpoint_path = pretrain_regular_dir/f'checkpoint-{N_EPOCHS}.pth'\nsearch_space.load_state_dict(\n    torch.load(checkpoint_path, map_location='cuda')['model']\n)\n# pretrain arcface search_space\npretrain(\n    search_space=search_space,\n    exp_dir=pretrain_arcface_dir,\n    train_loader=pretrain_and_tune_arcface_train_dataloader,\n    valid_loader=pretrain_and_tune_validation_dataloader,\n    optimizer=optimizer,\n    metric_function=accuracy,\n    loss_function=loss_function,\n    epochs=N_TUNE_EPOCHS,\n)\nif USE_CHECKPOINTS_FROM_GOOGLE_DRIVE:\n    # download arcface pretrain checkpoint from google drive\n    checkpoint_path = pretrain_arcface_dir / 'arcface_checkpoint.pth'\n    download_metric_learning_arcface_pretrain_checkpoint(checkpoint_path)\n    search_space.load_state_dict(\n        torch.load(checkpoint_path)['model'],\n    )\n# calculate distance between classes for arcface model\navg_cosine_dist_to_centroids_af = calc_avg_cosine_dist_to_centroids(\n    search_space=search_space, \n    dataloader=pretrain_and_tune_validation_dataloader, \n)","metadata":{"scrolled":true,"cellId":"j12e7o7anrn98z027l6ryv"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 6. Check arcface profit\nAverage cosine distance to centroids for regular model should be greater than for arcface model.","metadata":{"cellId":"5d8hu0zo8k8cmp53e0yk47"}},{"cell_type":"code","source":"print('#  REGULAR  ARCFACE')\nfor i, (reg, af) in enumerate(zip(avg_cosine_dist_to_centroids_reg, avg_cosine_dist_to_centroids_af)):\n    print(f'{i}  {reg:.4f}  {af:.4f}')","metadata":{"cellId":"ka5g2iy87jo3nufhjtvmxi"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 7. Search best architecture\nWe will use final network without any angle_margin, so we should search it is as regular model (dataloader without labels)","metadata":{"cellId":"die55nplnweuulfij8gqj"}},{"cell_type":"code","source":"# define directory for text logs and tensorboard logs\nsearch_dir = PROJECT_DIR / 'search'\nsearch_dir.mkdir(exist_ok=True)\n\noptimizer = RAdam(search_space.architecture_parameters(), lr=0.01)\n\nsearch(\n    search_space=search_space,\n    exp_dir=search_dir,\n    search_loader=search_train_dataloader,\n    valid_loader=search_validation_dataloader,\n    optimizer=optimizer,\n    loss_function=loss_function,\n    metric_function=accuracy,\n    epochs=5,\n)","metadata":{"scrolled":true,"cellId":"uo1ah5r986j86v3oq2pxq"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 8. Tune model with best architecture\nTune final model with angle_margin=0.1","metadata":{"cellId":"gzwmo9mhtykhsnjrv3ygtp"}},{"cell_type":"code","source":"# get regular model with best architecture\nbest_model = search_space.get_network_with_best_arch().cuda()","metadata":{"cellId":"411k1978j68mya2qwyrvy"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# define directory for text logs and tensorboard logs\ntune_dir = PROJECT_DIR / 'tune'\ntune_dir.mkdir(exist_ok=True)\n\noptimizer = RAdam(best_model.parameters(), lr=5e-3, weight_decay=4e-5)\n\ntrain(\n    model=best_model,\n    exp_dir=tune_dir,\n    train_loader=pretrain_and_tune_arcface_train_dataloader,\n    valid_loader=pretrain_and_tune_validation_dataloader,\n    optimizer=optimizer,\n    loss_function=loss_function,\n    metric_function=accuracy,\n    epochs=5,\n)","metadata":{"cellId":"a53wol3dwqk8kdg4kicwlb"},"outputs":[],"execution_count":null}]}