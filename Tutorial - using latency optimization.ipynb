{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using latency optimization with custom operations\n",
    "\n",
    "Here we describe the additional steps required to enable latency optimization in your model.\n",
    "\n",
    "### Notebook consists of next main stages:\n",
    "1. Setup the environment\n",
    "1. Add a custom non searchable operation/module with latency to use with search space\n",
    "1. Add a custom searchable operation with latency to use with search space\n",
    "1. Build model with custom operation\n",
    "1. Check pretrain search and tune phases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup the environment\n",
    "First, let's set up the environment and common imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['CUDA_DEVICE_ORDER']='PCI_BUS_ID'\n",
    "# You should change to free GPU\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.optim import SGD\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch_optimizer import RAdam\n",
    "from torchvision.models.mobilenet import ConvBNReLU\n",
    "\n",
    "from enot.models import BaseSearchableOperation\n",
    "from enot.models import build_simple_block_model\n",
    "from enot.models import register_searchable_op\n",
    "from enot.models import SearchSpaceModel\n",
    "from enot.phases import pretrain\n",
    "from enot.phases import search\n",
    "from enot.phases import train\n",
    "from enot.utils.latency import conv_mac_count\n",
    "from enot.utils.latency import LatencyMixin\n",
    "\n",
    "from enot_utils.metric_utils import accuracy\n",
    "from enot_utils.schedulers import WarmupScheduler\n",
    "\n",
    "from tutorial_utils.dataset import create_imagenette_dataloaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Add a custom non searchable operation/module with latency to use with search space\n",
    "\n",
    "To add latency support to your custom regular operation/module, you need to implement latency calculation.\n",
    "\n",
    "Adding latency calculation is done in two steps:\n",
    "1. Make your class a child of `enot.utils.latency.LatencyMixin`. `LatencyMixin` offer interface of latency calculation for `SearchSpaceModel` using user defined methods of latency calculations (see next step).\n",
    "2. Add a method with a signature `latency_<name>(self, spatial_size) -> float`, which calculates latency.\n",
    "\n",
    "At this moment only `'mmac'` (millions of multiply-accumulates) is supported."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Head and stem of your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyStem(ConvBNReLU, LatencyMixin):\n",
    "    def __init__(\n",
    "            self,\n",
    "            in_channels,\n",
    "            out_channels,\n",
    "            kernel_size=3,\n",
    "            stride=1,\n",
    "            groups=1,\n",
    "            norm_layer=None,\n",
    "    ):\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.groups = groups\n",
    "        \n",
    "        super().__init__(in_channels, out_channels, kernel_size, stride, groups, norm_layer)\n",
    "    \n",
    "    def latency_mmac(self, spatial_size):\n",
    "        \"\"\"Calculate millions of multiply-accumulates\"\"\"\n",
    "        mmac, _ = conv_mac_count(\n",
    "            spatial_size=spatial_size,\n",
    "            kernel_size=self.kernel_size,\n",
    "            stride=self.stride,\n",
    "            in_channels=self.in_channels,\n",
    "            padding=0,\n",
    "            out_channels=self.out_channels,\n",
    "            groups=self.groups,\n",
    "        )\n",
    "        \n",
    "        return mmac\n",
    "    \n",
    "    \n",
    "class MyHead(nn.Sequential, LatencyMixin):\n",
    "    def __init__(\n",
    "        self, \n",
    "        in_channels,\n",
    "        hidden_channels,\n",
    "        num_classes,\n",
    "        dropout_rate=0.2\n",
    "    ):\n",
    "        self.in_channels = in_channels\n",
    "        self.hidden_channels = hidden_channels\n",
    "        self.num_classes = num_classes\n",
    "        \n",
    "        super().__init__(\n",
    "            ConvBNReLU(in_channels, hidden_channels, kernel_size=1),\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_channels, num_classes)\n",
    "        )\n",
    "      \n",
    "    def latency_mmac(self, spatial_size):\n",
    "        \"\"\"Calculate millions of multiply-accumulates\"\"\"\n",
    "        mmac, (h_out, w_out) = conv_mac_count(spatial_size, 1, 1, self.in_channels, 0, self.hidden_channels)\n",
    "        mmac += h_out * w_out * self.hidden_channels / 10**6\n",
    "        mmac += self.hidden_channels * self.num_classes / 10**6\n",
    "        \n",
    "        return mmac"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Add a custom searchable operation with latency to use with search space\n",
    "\n",
    "We will re-implement our custom operation with latency support. All details of adding custom operation can be found in \"Tutorial - adding custom ops\".\n",
    "\n",
    "**IMPORTANT**:<br>\n",
    "`BaseSearchableOperation` is child of `LatencyMixin`, so you only need to add a method with a signature `latency_<name>(self, spatial_size) -> float` which calculates latency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define short parameter parsing rules\n",
    "# Format: {short_param_name: (original_param_name, parser)}\n",
    "short_args = {\n",
    "    'k': ('kernel_size', int),\n",
    "}\n",
    "\n",
    "\n",
    "@register_searchable_op('MyOp', short_args)\n",
    "class MyOperation(BaseSearchableOperation):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels,\n",
    "        out_channels,\n",
    "        stride,\n",
    "        kernel_size=3,\n",
    "        padding=None,   \n",
    "        use_skip_connection=True\n",
    "    ):\n",
    "        super().__init__(\n",
    "            in_channels,\n",
    "            out_channels,\n",
    "            use_skip_connection,\n",
    "        )\n",
    "            \n",
    "        if padding is None:\n",
    "            padding = (kernel_size - 1) // 2\n",
    "        \n",
    "        self.stride = stride\n",
    "        self.kernel_size = kernel_size\n",
    "        self.padding = padding\n",
    "        \n",
    "        self.operation = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=in_channels, \n",
    "                out_channels=out_channels, \n",
    "                kernel_size=kernel_size, \n",
    "                stride=stride, \n",
    "                padding=padding,\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(out_channels)\n",
    "        )\n",
    "\n",
    "    def get_last_batch_norm(self) -> nn.BatchNorm2d:\n",
    "        return self.operation[-1]\n",
    "\n",
    "    def replace_last_batch_norm(self, new_last_batch_norm: nn.BatchNorm2d) -> None:\n",
    "        self.operation[-1] = new_last_batch_norm\n",
    "        \n",
    "    def operation_forward(self, x):\n",
    "        return self.operation(x)\n",
    "        \n",
    "    def latency_mmac(self, spatial_size):\n",
    "        \"\"\"Calculate number of millions of multiply-accumulate operations in MyOperation\"\"\"\n",
    "        \n",
    "        def num_conv_steps(size, padding, kernel, stride):\n",
    "            size = size + 2 * padding - (kernel - 1)\n",
    "            return (size + stride - 1) // stride\n",
    "\n",
    "        h, w = spatial_size\n",
    "        h_steps = num_conv_steps(h, self.padding, self.kernel_size, self.stride)\n",
    "        w_steps = num_conv_steps(w, self.padding, self.kernel_size, self.stride)\n",
    "        mmac = h_steps * w_steps * self.kernel_size**2 * self.in_channels * self.out_channels\n",
    "        mmac /= 10**6\n",
    "        \n",
    "        return mmac"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Build model with custom operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEARCH_OPS = [\n",
    "    'MIB_k=3_t=6',\n",
    "    'MIB_k=5_t=6',\n",
    "    'MyOp_k=3',\n",
    "]\n",
    "\n",
    "blocks_in_channels = 32\n",
    "blocks_out_channels = 320\n",
    "head_hidden_channels = 1280\n",
    "num_classes = 10\n",
    "\n",
    "# build model\n",
    "model = build_simple_block_model(\n",
    "    in_channels=blocks_in_channels,\n",
    "    search_ops=SEARCH_OPS,\n",
    "    blocks_out_channels=[24, 32, 64, 96, 160, blocks_out_channels],\n",
    "    blocks_count=[2, 2, 2, 1, 2, 1],\n",
    "    blocks_stride=[2, 2, 2, 1, 2, 1],\n",
    "    stem=MyStem(in_channels=3, out_channels=blocks_in_channels, stride=2),\n",
    "    head=MyHead(in_channels=blocks_out_channels, hidden_channels=head_hidden_channels, num_classes=num_classes),\n",
    ")\n",
    "# move model to search space\n",
    "search_space = SearchSpaceModel(model).cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Check pretrain search and tune phases\n",
    "\n",
    "Let's check that everything works.\n",
    "\n",
    "**IMPORTANT**:<br>\n",
    "To turn on latency optimization you must set `latency_loss_weight` (> 0) parameter of `search`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENOT_HOME_DIR = Path.home() / '.enot'\n",
    "ENOT_DATASETS_DIR = ENOT_HOME_DIR / 'datasets'\n",
    "PROJECT_DIR = ENOT_HOME_DIR / 'using_latency_optimization'\n",
    "\n",
    "ENOT_HOME_DIR.mkdir(exist_ok=True)\n",
    "ENOT_DATASETS_DIR.mkdir(exist_ok=True)\n",
    "PROJECT_DIR.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = create_imagenette_dataloaders(\n",
    "    dataset_root_dir=ENOT_DATASETS_DIR, \n",
    "    project_dir=PROJECT_DIR,\n",
    "    input_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    imagenette_kind='imagenette2-320',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# define directory for text logs and tensorboard logs\n",
    "pretrain_dir = PROJECT_DIR / 'pretrain'\n",
    "pretrain_dir.mkdir(exist_ok=True)\n",
    "\n",
    "N_EPOCHS = 3\n",
    "N_WARMUP_EPOCHS = 1\n",
    "len_train = len(dataloaders['pretrain_train_dataloader'])\n",
    "\n",
    "optimizer = SGD(params=search_space.model_parameters(), lr=0.06, momentum=0.9, weight_decay=1e-4)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=len_train*N_EPOCHS, eta_min=1e-8)\n",
    "scheduler = WarmupScheduler(scheduler, warmup_steps=len_train*N_WARMUP_EPOCHS)\n",
    "loss_function = nn.CrossEntropyLoss().cuda()\n",
    "\n",
    "pretrain(\n",
    "    search_space=search_space,\n",
    "    exp_dir=pretrain_dir,\n",
    "    train_loader=dataloaders['pretrain_train_dataloader'],\n",
    "    valid_loader=dataloaders['pretrain_validation_dataloader'],\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    metric_function=accuracy,\n",
    "    loss_function=loss_function,\n",
    "    epochs=N_EPOCHS,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# define directory for text logs and tensorboard logs\n",
    "search_dir = PROJECT_DIR / 'search'\n",
    "search_dir.mkdir(exist_ok=True)\n",
    "\n",
    "optimizer = RAdam(search_space.architecture_parameters(), lr=0.01)\n",
    "\n",
    "search(\n",
    "    search_space=search_space,\n",
    "    exp_dir=search_dir,\n",
    "    search_loader=dataloaders['search_train_dataloader'],\n",
    "    valid_loader=dataloaders['search_validation_dataloader'],\n",
    "    optimizer=optimizer,\n",
    "    loss_function=loss_function,\n",
    "    metric_function=accuracy,\n",
    "    latency_loss_weight=2.0e-3,\n",
    "    epochs=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get regular model with best architecture\n",
    "best_model = search_space.get_network_with_best_arch().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define directory for text logs and tensorboard logs\n",
    "tune_dir = PROJECT_DIR / 'tune'\n",
    "tune_dir.mkdir(exist_ok=True)\n",
    "\n",
    "optimizer = RAdam(best_model.parameters(), lr=5e-3, weight_decay=4e-5)\n",
    "\n",
    "train(\n",
    "    model=best_model,\n",
    "    exp_dir=tune_dir,\n",
    "    train_loader=dataloaders['tune_train_dataloader'],\n",
    "    valid_loader=dataloaders['tune_validation_dataloader'],\n",
    "    optimizer=optimizer,\n",
    "    loss_function=loss_function,\n",
    "    metric_function=accuracy,\n",
    "    epochs=3,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
