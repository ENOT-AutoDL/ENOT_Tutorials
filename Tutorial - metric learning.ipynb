{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Arcface head for search best architecture on metric learning task\n",
    "\n",
    "### Notebook consists of next main stages:\n",
    "1. Setup the environment\n",
    "1. Define ArcfaceHead class and define MetricLearningModel class\n",
    "1. Prepare dataloaders\n",
    "1. Create the model and move it to search space\n",
    "1. Pretrain search_space\n",
    "1. Search best architecture\n",
    "1. Tune model with best architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy your license file to $HOME/.enot/enot.lic or set full path to licence file \n",
    "# through environment variable ENOT_LIC_FILE\n",
    "#\n",
    "# Important note: no quotes\n",
    "# %env ENOT_LIC_FILE=/FULL/PATH/TO/your_company.lic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['CUDA_DEVICE_ORDER']='PCI_BUS_ID'\n",
    "# You should change to free GPU\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from torch.optim import SGD\n",
    "from torch_optimizer import RAdam\n",
    "\n",
    "from torchvision.models.mobilenet import ConvBNReLU\n",
    "\n",
    "from enot.models import build_simple_block_model\n",
    "from enot.models import SearchSpaceModel\n",
    "from enot.phases import pretrain\n",
    "from enot.phases import search\n",
    "from enot.phases import train\n",
    "from enot.utils.data.csv_annotation_dataset import CsvAnnotationDataset\n",
    "from enot.utils.data.dataloaders import create_data_loader\n",
    "from enot.utils.data.dataloaders import create_data_loader_from_csv_annotation\n",
    "\n",
    "from tutorial_utils.checkpoints import download_metric_learning_arcface_pretrain_checkpoint\n",
    "from tutorial_utils.checkpoints import download_metric_learning_regular_pretrain_checkpoint\n",
    "from tutorial_utils.dataset import create_imagenette_annotation\n",
    "from tutorial_utils.dataset import download_imagenette\n",
    "from tutorial_utils.dataset import create_imagenette_train_transform\n",
    "from tutorial_utils.dataset import create_imagenette_validation_transform\n",
    "\n",
    "from enot_utils.metric_utils import accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define ArcfaceHead class and define MetricLearningModel class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArcfaceHead(nn.Linear):\n",
    "    def __init__(\n",
    "            self,\n",
    "            in_channels: int,\n",
    "            *,\n",
    "            radius=64.0,\n",
    "            angle_margin=0.5,\n",
    "            embedding_channels=512,\n",
    "            num_classes=10,\n",
    "    ):\n",
    "        super().__init__(embedding_channels, num_classes, bias=False)\n",
    "\n",
    "        self.radius = radius\n",
    "        self.angle_margin = angle_margin\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        self.vectorizer = nn.Sequential(\n",
    "            ConvBNReLU(\n",
    "                in_channels, \n",
    "                embedding_channels,\n",
    "                1, 1, 1, norm_layer=None,\n",
    "            ),\n",
    "            nn.AdaptiveAvgPool2d([1, 1]),\n",
    "            nn.Flatten(),\n",
    "        )\n",
    "\n",
    "    def forward(self, inputs, labels=None):\n",
    "        features = F.normalize(self.vectorizer(inputs), 2, -1)\n",
    "\n",
    "        weights = F.normalize(self.weight, 2, -1)\n",
    "        cosine = F.linear(features, weights)\n",
    "\n",
    "        if labels is not None:\n",
    "            angle = torch.acos(cosine)\n",
    "            modified_cos = torch.cos(angle + self.angle_margin)\n",
    "\n",
    "            one_hot = torch.zeros(cosine.size(), device=cosine.device)\n",
    "            one_hot.scatter_(1, labels.view(-1, 1).long(), 1)\n",
    "            cosine = cosine * (1 - one_hot) + modified_cos * one_hot\n",
    "\n",
    "        return cosine * self.radius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetricLearningModel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        search_ops,\n",
    "        embedding_channels=512,\n",
    "        num_classes=10,\n",
    "        radius=64.0,\n",
    "        angle_margin=0.0,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        blocks_in_channels = 32\n",
    "        blocks_out_channels = 320\n",
    "\n",
    "        self.stem = ConvBNReLU(3, blocks_in_channels, stride=2)\n",
    "        self.body = build_simple_block_model(\n",
    "            in_channels=blocks_in_channels,\n",
    "            search_ops=search_ops,\n",
    "            blocks_out_channels=[16, 24, 32, 64, 96, 160, blocks_out_channels],\n",
    "            blocks_count=[1, 2, 2, 2, 1, 2, 1],\n",
    "            blocks_stride=[1, 2, 2, 2, 1, 2, 1],\n",
    "            width_multiplier=1.0,\n",
    "            min_channels=8,\n",
    "            init_weights_kn=True,\n",
    "        )\n",
    "        self.head = ArcfaceHead(\n",
    "            blocks_out_channels,\n",
    "            radius=radius,\n",
    "            angle_margin=angle_margin,\n",
    "            embedding_channels=embedding_channels,\n",
    "            num_classes=num_classes,\n",
    "        )\n",
    "\n",
    "    def update_angle_margin(self, value):\n",
    "        self.head.angle_margin = value\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        labels = None\n",
    "        if not isinstance(inputs, torch.Tensor):\n",
    "            inputs, labels = inputs\n",
    "\n",
    "        x = self.stem(inputs)\n",
    "        x = self.body(x)\n",
    "        x = self.head(x, labels)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Prepare dataloaders\n",
    "For arcface training we need to pass labels to head part of the model, so arcface train `Dataset` must return data in the next format `(image, label), label`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ENOT_HOME_DIR = Path.home() / '.enot'\n",
    "ENOT_DATASETS_DIR = ENOT_HOME_DIR / 'datasets'\n",
    "PROJECT_DIR = ENOT_HOME_DIR / 'metric_learning'\n",
    "\n",
    "ENOT_HOME_DIR.mkdir(exist_ok=True)\n",
    "ENOT_DATASETS_DIR.mkdir(exist_ok=True)\n",
    "PROJECT_DIR.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArcfaceTrainCsvAnnotationDataset(CsvAnnotationDataset):\n",
    "    def __init__(self, csv_annotation_path, root_dir=None, transform=None):\n",
    "        super().__init__(csv_annotation_path, root_dir=root_dir, transform=transform)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image, label = super().__getitem__(idx)\n",
    "        return (image, label), label\n",
    "\n",
    "\n",
    "num_workers = 4\n",
    "input_size = (224, 224)\n",
    "batch_size = 32\n",
    "dataset_dir = download_imagenette(\n",
    "    dataset_root_dir=ENOT_DATASETS_DIR, imagenette_kind='imagenette2-320',\n",
    ")\n",
    "annotations = create_imagenette_annotation(\n",
    "    dataset_dir=dataset_dir, project_dir=PROJECT_DIR, random_seed=42,\n",
    ")\n",
    "train_transform = create_imagenette_train_transform(input_size)\n",
    "validation_transform = create_imagenette_validation_transform(input_size)\n",
    "\n",
    "pretrain_and_tune_train_dataloader = create_data_loader_from_csv_annotation(\n",
    "    csv_annotation_path=annotations['train'],\n",
    "    dataset_transform=train_transform,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    shuffle=True,\n",
    ")\n",
    "pretrain_and_tune_arcface_train_dataloader = create_data_loader(\n",
    "    dataset=ArcfaceTrainCsvAnnotationDataset(annotations['train'], transform=train_transform),\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    shuffle=True,\n",
    "    collate_fn=None,\n",
    ")\n",
    "pretrain_and_tune_validation_dataloader = create_data_loader_from_csv_annotation(\n",
    "    csv_annotation_path=annotations['validation'],\n",
    "    dataset_transform=validation_transform,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "search_train_dataloader = create_data_loader_from_csv_annotation(\n",
    "    csv_annotation_path=annotations['search'],\n",
    "    dataset_transform=train_transform,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    shuffle=True,\n",
    ")\n",
    "search_validation_dataloader = create_data_loader_from_csv_annotation(\n",
    "    csv_annotation_path=annotations['search'],\n",
    "    dataset_transform=validation_transform,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create the model and move it to search space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEARCH_OPS = [\n",
    "    'MIB_k=3_t=3',\n",
    "    'MIB_k=3_t=6',\n",
    "]\n",
    "\n",
    "# build model\n",
    "model = MetricLearningModel(search_ops=SEARCH_OPS, angle_margin=0.1)\n",
    "# move model to search space\n",
    "search_space = SearchSpaceModel(model, train_loader=pretrain_and_tune_train_dataloader).cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Pretrain search_space\n",
    "\n",
    "Pretrain procedure stages:\n",
    "1. We pretrain regular search_space (use regular train dataloader `pretrain_and_tune_train_dataloader`)\n",
    "1. Calculate avg cosine distance to centroid for all classes\n",
    "1. We pretrain arcface search_space with angle_margin=0.1 (use arcface train dataloader `pretrain_and_tune_arcface_train_dataloader`, which returns labels)\n",
    "1. Calculate avg cosine distance to centroid for all classes\n",
    "\n",
    "**IMPORTANT:**<br>\n",
    "We cannot start training of arcface search_space from the randomly initialized search_space, because it is not efficient. Arcface pretrain starts from pretrained regular model and just tune it. For fair comparison we use next train procedure:<br>\n",
    "```\n",
    "1-2-3-4-...-N_EPOCHS-...-N_EPOCHS+N_TUNE_EPOCHS <- Regular model\n",
    "               |\n",
    "         load checkpoint\n",
    "               |\n",
    "               1-...N_TUNE_EPOCHS <- Arcface model\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function, which calculate avg cosine distance to centroid for all classes\n",
    "def calc_avg_cosine_dist_to_centroids(search_space, dataloader, num_classes=10, forward_indices=None):\n",
    "    avg_distances = [(0.0, 0) for i in range(num_classes)]\n",
    "\n",
    "    # We should fixate architecture of search space. It can be any architecture, but \n",
    "    # must be the same for arcface and regular models\n",
    "    if forward_indices is None:\n",
    "        n = len(search_space.search_variants_containers)\n",
    "        forward_indices = [[0] for _ in range(n)]\n",
    "\n",
    "    search_space.eval()\n",
    "    search_space.sample(forward_indices=forward_indices)\n",
    "\n",
    "    radius = search_space.original_model.head.radius\n",
    "    for inputs, labels in dataloader:\n",
    "        labels = labels.detach().cpu().numpy()\n",
    "        current_result = search_space(inputs)\n",
    "        current_result = current_result.detach().cpu().numpy()\n",
    "\n",
    "        for one_result, one_label in zip(current_result, labels):\n",
    "            # get \n",
    "            dist, n = avg_distances[one_label]\n",
    "            # update\n",
    "            current_dist = 1 - one_result[one_label]/radius\n",
    "            dist += current_dist\n",
    "            n += 1\n",
    "            # set updated\n",
    "            avg_distances[one_label] = dist, n\n",
    "\n",
    "    for i in range(num_classes):\n",
    "        dist, n = avg_distances[i]\n",
    "        avg_distances[i] = dist/n if n != 0 else 0.0\n",
    "\n",
    "    return avg_distances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IMPORTANT:**<br>\n",
    "(N_EPOCHS + N_TUNE_EPOCHS) should be ~(100 + 30), if you wanna get good pretrain. In this tutorial we set (N_EPOCHS + N_TUNE_EPOCHS) = (2 + 1) and download checkpoints of pretreined models from Google Drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# define directory for text logs and tensorboard logs\n",
    "pretrain_regular_dir = PROJECT_DIR / 'pretrain_regular'\n",
    "pretrain_regular_dir.mkdir(exist_ok=True)\n",
    "pretrain_arcface_dir = PROJECT_DIR / 'pretrain_arcface'\n",
    "pretrain_arcface_dir.mkdir(exist_ok=True)\n",
    "\n",
    "N_EPOCHS = 10\n",
    "N_TUNE_EPOCHS = 1\n",
    "USE_CHECKPOINTS_FROM_GOOGLE_DRIVE = True\n",
    "\n",
    "optimizer = SGD(\n",
    "    params=search_space.model_parameters(), \n",
    "    lr=0.01, \n",
    "    momentum=0.9, \n",
    "    weight_decay=1e-4\n",
    ")\n",
    "loss_function = nn.CrossEntropyLoss().cuda()\n",
    "\n",
    "# pretrain regular search_space\n",
    "pretrain(\n",
    "    search_space=search_space,\n",
    "    exp_dir=pretrain_regular_dir,\n",
    "    train_loader=pretrain_and_tune_train_dataloader,\n",
    "    valid_loader=pretrain_and_tune_validation_dataloader,\n",
    "    optimizer=optimizer,\n",
    "    metric_function=accuracy,\n",
    "    loss_function=loss_function,\n",
    "    epochs=N_EPOCHS + N_TUNE_EPOCHS,\n",
    ")\n",
    "if USE_CHECKPOINTS_FROM_GOOGLE_DRIVE:\n",
    "    # download regular pretrain checkpoint from google drive\n",
    "    checkpoint_path = pretrain_regular_dir / 'regular_checkpoint.pth'\n",
    "    download_metric_learning_regular_pretrain_checkpoint(checkpoint_path)\n",
    "    search_space.load_state_dict(\n",
    "        torch.load(checkpoint_path)['model'],\n",
    "    )\n",
    "# calculate distance between classes for regular model\n",
    "avg_cosine_dist_to_centroids_reg = calc_avg_cosine_dist_to_centroids(\n",
    "    search_space=search_space, \n",
    "    dataloader=pretrain_and_tune_validation_dataloader, \n",
    ")\n",
    "\n",
    "# load checkpoint for tune\n",
    "checkpoint_path = pretrain_regular_dir/f'checkpoint-{N_EPOCHS}.pth'\n",
    "search_space.load_state_dict(\n",
    "    torch.load(checkpoint_path, map_location='cuda')['model']\n",
    ")\n",
    "# pretrain arcface search_space\n",
    "pretrain(\n",
    "    search_space=search_space,\n",
    "    exp_dir=pretrain_arcface_dir,\n",
    "    train_loader=pretrain_and_tune_arcface_train_dataloader,\n",
    "    valid_loader=pretrain_and_tune_validation_dataloader,\n",
    "    optimizer=optimizer,\n",
    "    metric_function=accuracy,\n",
    "    loss_function=loss_function,\n",
    "    epochs=N_TUNE_EPOCHS,\n",
    ")\n",
    "if USE_CHECKPOINTS_FROM_GOOGLE_DRIVE:\n",
    "    # download arcface pretrain checkpoint from google drive\n",
    "    checkpoint_path = pretrain_arcface_dir / 'arcface_checkpoint.pth'\n",
    "    download_metric_learning_arcface_pretrain_checkpoint(checkpoint_path)\n",
    "    search_space.load_state_dict(\n",
    "        torch.load(checkpoint_path)['model'],\n",
    "    )\n",
    "# calculate distance between classes for arcface model\n",
    "avg_cosine_dist_to_centroids_af = calc_avg_cosine_dist_to_centroids(\n",
    "    search_space=search_space, \n",
    "    dataloader=pretrain_and_tune_validation_dataloader, \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Check arcface profit\n",
    "Average cosine distance to centroids for regular model should be greater than for arcface model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('#  REGULAR  ARCFACE')\n",
    "for i, (reg, af) in enumerate(zip(avg_cosine_dist_to_centroids_reg, avg_cosine_dist_to_centroids_af)):\n",
    "    print(f'{i}  {reg:.4f}  {af:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Search best architecture\n",
    "We will use final network without any angle_margin, so we should search it is as regular model (dataloader without labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# define directory for text logs and tensorboard logs\n",
    "search_dir = PROJECT_DIR / 'search'\n",
    "search_dir.mkdir(exist_ok=True)\n",
    "\n",
    "optimizer = RAdam(search_space.architecture_parameters(), lr=0.01)\n",
    "\n",
    "search(\n",
    "    search_space=search_space,\n",
    "    exp_dir=search_dir,\n",
    "    search_loader=search_train_dataloader,\n",
    "    valid_loader=search_validation_dataloader,\n",
    "    optimizer=optimizer,\n",
    "    loss_function=loss_function,\n",
    "    metric_function=accuracy,\n",
    "    epochs=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Tune model with best architecture\n",
    "Tune final model with angle_margin=0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get regular model with best architecture\n",
    "best_model = search_space.get_network_with_best_arch().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# define directory for text logs and tensorboard logs\n",
    "tune_dir = PROJECT_DIR / 'tune'\n",
    "tune_dir.mkdir(exist_ok=True)\n",
    "\n",
    "optimizer = RAdam(best_model.parameters(), lr=5e-3, weight_decay=4e-5)\n",
    "\n",
    "train(\n",
    "    model=best_model,\n",
    "    exp_dir=tune_dir,\n",
    "    train_loader=pretrain_and_tune_arcface_train_dataloader,\n",
    "    valid_loader=pretrain_and_tune_validation_dataloader,\n",
    "    optimizer=optimizer,\n",
    "    loss_function=loss_function,\n",
    "    metric_function=accuracy,\n",
    "    epochs=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "enot_venv",
   "language": "python",
   "name": ".enot_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
