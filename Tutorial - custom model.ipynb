{"nbformat":4,"nbformat_minor":4,"metadata":{"kernelspec":{"name":"python3","display_name":"Yandex DataSphere Kernel","language":"python"},"language_info":{"file_extension":".py","version":"3.7.7","mimetype":"text/x-python","codemirror_mode":{"version":3,"name":"ipython"},"name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3"},"notebookId":"0861ee80-1a4a-4ab8-92d8-31bfd3478f70"},"cells":[{"cell_type":"markdown","source":"## Custom modelÂ \nIn this notebook we describe how you can implement your own model. The model which can not be built by \"block models builders\" from framework.\n\n### Notebook consists of next main stages:\n1. Setup the environment\n1. Define, create the model and move it to search space\n1. Prepare dataset and create dataloaders\n1. Check pretrain, search and tune phases","metadata":{"cellId":"reidguewueoookmmsq73"}},{"cell_type":"markdown","source":"## 1. Setup the environment\nFirst, let's set up the environment and common imports.","metadata":{"cellId":"prgduw4tujrk62o1i4arac"}},{"cell_type":"code","source":"import sys\n\nsys.path.append('ENOT_Tutorials')","metadata":{"cellId":"iy2rykzrhamjsybnc24r19"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from pathlib import Path\n\nimport torch\nimport torch.nn as nn\n\nfrom torch.optim import SGD\nfrom torch.optim.lr_scheduler import CosineAnnealingLR\nfrom torch_optimizer import RAdam\n\nfrom enot.models import SearchSpaceModel\nfrom enot.models.mobilenet import MobileNetBaseHead\nfrom enot.models.mobilenet import MobileNetBaseStem\nfrom enot.models.operations import SearchableMobileInvertedBottleneck\nfrom enot.models.operations import SearchableFuseableSkipConv\nfrom enot.models.operations import SearchVariantsContainer\nfrom enot.phases import pretrain\nfrom enot.phases import search\nfrom enot.phases import train\n\nfrom enot_utils.metric_utils import accuracy\nfrom enot_utils.schedulers import WarmupScheduler\n\nfrom tutorial_utils.checkpoints import download_getting_started_pretrain_checkpoint\nfrom tutorial_utils.dataset import create_imagenette_dataloaders","metadata":{"cellId":"2rx02kdv8yyikt21xiph2s"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### In the next cell we setup all required dirs\n\n* `ENOT_HOME_DIR` - is root dir for all other dirs\n* `ENOT_DATASETS_DIR` - is root dir for datasets (imagenette2)\n* `PROJECT_DIR` - is root dir for output data (checkpoints, logs...) of current tutorial","metadata":{"cellId":"6q8tee7ztpeced190wabdb"}},{"cell_type":"code","source":"ENOT_HOME_DIR = Path.home() / '.enot'\nENOT_DATASETS_DIR = ENOT_HOME_DIR / 'datasets'\nPROJECT_DIR = ENOT_HOME_DIR / 'custom_model'\n\nENOT_HOME_DIR.mkdir(exist_ok=True)\nENOT_DATASETS_DIR.mkdir(exist_ok=True)\nPROJECT_DIR.mkdir(exist_ok=True)","metadata":{"cellId":"hnmyjd6wrmqodg4gtqv4t"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 2. Create the model and move it to search space\nTo create your custom model you should build it as common pytorch model with the following rules:\n1. Search variants must be placed in `SearchVariantsContainer` module.\n2. All `SearchVariantsContainer` must contain the same number of operations. Operations of different containers can be different, but all containers must contain the same number of operations. **This restriction will be removed in the future versions.**\n3. Every operation in SearchVariantsContainer must be child of `BaseSearchableOperation` class, so you can use predefined operations from framework (`enot.model.operations`) or create your custom operation (see \"Tutorial - adding custom ops\")","metadata":{"cellId":"5v3v5woeulnrk7vtn5ad6h"}},{"cell_type":"code","source":"class MyModel(nn.Module):\n    def __init__(self):\n        super().__init__()\n        \n        self.stem = MobileNetBaseStem(\n            in_channels=3\n        )\n        self.body = nn.ModuleList([\n            # 3 blocks with 3 search variants in every block \n            self.build_search_variants_1(16, 24, 2),\n            self.build_search_variants_1(24, 24, 1),\n            self.build_search_variants_1(24, 24, 1),\n            # 2 fixed blocks\n            self.build_mib_k3_e6(24, 32, 2),\n            self.build_mib_k3_e6(32, 32, 1),\n            # 3 blocks with 3 search variants in every block\n            self.build_search_variants_1(32, 64, 2),\n            self.build_search_variants_1(64, 64, 1),\n            self.build_search_variants_1(64, 64, 1),\n            # 1 fixed block\n            self.build_mib_k3_e6(64, 96, 1),\n            # 2 blocks with 3 search variants in every block\n            self.build_search_variants_2(96, 160, 2),\n            self.build_search_variants_2(160, 160, 1),\n            # 1 block with 3 search variants\n            self.build_search_variants_2(160, 320, 1),\n        ])\n        self.head = MobileNetBaseHead(\n            bottleneck_channels=320,\n            last_channels=1280, \n            num_classes=10,\n        )\n    \n    @staticmethod\n    def build_search_variants_1(in_channels, out_channels, stride):\n        return SearchVariantsContainer([\n            SearchableMobileInvertedBottleneck(\n                in_channels=in_channels,\n                out_channels=out_channels,\n                kernel_size=3,\n                stride=stride,\n                expand_ratio=6,\n            ),\n            SearchableMobileInvertedBottleneck(\n                in_channels=in_channels,\n                out_channels=out_channels,\n                kernel_size=5,\n                stride=stride,\n                expand_ratio=6,\n            ),\n            SearchableMobileInvertedBottleneck(\n                in_channels=in_channels,\n                out_channels=out_channels,\n                kernel_size=7,\n                stride=stride,\n                expand_ratio=3,\n            ),\n        ])\n\n    @staticmethod\n    def build_search_variants_2(in_channels, out_channels, stride):\n        return SearchVariantsContainer([\n            SearchableMobileInvertedBottleneck(\n                in_channels=in_channels,\n                out_channels=out_channels,\n                kernel_size=3,\n                stride=stride,\n                expand_ratio=6,\n            ),\n            SearchableMobileInvertedBottleneck(\n                in_channels=in_channels,\n                out_channels=out_channels,\n                kernel_size=5,\n                stride=stride,\n                expand_ratio=6,\n            ),\n            SearchableFuseableSkipConv(\n                in_channels=in_channels,\n                out_channels=out_channels,\n                stride=stride,\n            ),\n        ])\n\n    @staticmethod\n    def build_mib_k3_e6(in_channels, out_channels, stride):\n        return SearchableMobileInvertedBottleneck(\n                in_channels=in_channels,\n                out_channels=out_channels,\n                kernel_size=3,\n                stride=stride,\n                expand_ratio=6,\n            )\n\n    def forward(self, x):\n        x = self.stem(x)\n        \n        for block in self.body:\n            x = block(x)\n            \n        x = self.head(x)\n        \n        return x\n    \nmodel = MyModel()\n# move model to search space\nsearch_space = SearchSpaceModel(model).cuda()","metadata":{"cellId":"51y141g03htq06uiwr4cc"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 3. Prepare dataset and create dataloaders","metadata":{"cellId":"dydd4gx9be0ngvogwry1"}},{"cell_type":"code","source":"dataloaders = create_imagenette_dataloaders(\n    dataset_root_dir=ENOT_DATASETS_DIR, \n    project_dir=PROJECT_DIR,\n    input_size=(224, 224),\n    batch_size=32,\n)","metadata":{"cellId":"mqv1pjexj3em2jq31jylj"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"## 4. Check pretrain, search and tune phases\n\n**IMPORTANT:**<br>\n`N_EPOCHS` of pretrain should be in range >= 100, if you wanna get good pretrain. In this tutorial we set `N_EPOCHS` = 3 and just check phases. ","metadata":{"cellId":"s46kxrc11wnqh7hr4k3gd8"}},{"cell_type":"code","source":"# define directory for text logs and tensorboard logs\npretrain_dir = PROJECT_DIR / 'pretrain'\npretrain_dir.mkdir(exist_ok=True)\n\nN_EPOCHS = 3\nN_WARMUP_EPOCHS = 1\nlen_train = len(dataloaders['pretrain_train_dataloader'])\n\noptimizer = SGD(params=search_space.model_parameters(), lr=0.06, momentum=0.9, weight_decay=1e-4)\nscheduler = CosineAnnealingLR(optimizer, T_max=len_train*N_EPOCHS, eta_min=1e-8)\nscheduler = WarmupScheduler(scheduler, warmup_steps=len_train*N_WARMUP_EPOCHS)\nloss_function = nn.CrossEntropyLoss().cuda()\n\npretrain(\n    search_space=search_space,\n    exp_dir=pretrain_dir,\n    train_loader=dataloaders['pretrain_train_dataloader'],\n    valid_loader=dataloaders['pretrain_validation_dataloader'],\n    optimizer=optimizer,\n    scheduler=scheduler,\n    metric_function=accuracy,\n    loss_function=loss_function,\n    epochs=N_EPOCHS,\n)","metadata":{"scrolled":true,"cellId":"z0ncfecd7n288hjhbwx24"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# define directory for text logs and tensorboard logs\nsearch_dir = PROJECT_DIR / 'search'\nsearch_dir.mkdir(exist_ok=True)\n\noptimizer = RAdam(search_space.architecture_parameters(), lr=0.01)\n\nsearch(\n    search_space=search_space,\n    exp_dir=search_dir,\n    search_loader=dataloaders['search_train_dataloader'],\n    valid_loader=dataloaders['search_validation_dataloader'],\n    optimizer=optimizer,\n    loss_function=loss_function,\n    metric_function=accuracy,\n    latency_loss_weight=2.0e-3,\n    epochs=5,\n)","metadata":{"scrolled":true,"cellId":"hk7g0tc7mqumns6m7txw59"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# get regular model with best architecture\nbest_model = search_space.get_network_with_best_arch().cuda()","metadata":{"cellId":"act5v2g6wd9qw2yqpneh2d"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# define directory for text logs and tensorboard logs\ntune_dir = PROJECT_DIR / 'tune'\ntune_dir.mkdir(exist_ok=True)\n\noptimizer = RAdam(best_model.parameters(), lr=5e-3, weight_decay=4e-5)\n\ntrain(\n    model=best_model,\n    exp_dir=tune_dir,\n    train_loader=dataloaders['tune_train_dataloader'],\n    valid_loader=dataloaders['tune_validation_dataloader'],\n    optimizer=optimizer,\n    loss_function=loss_function,\n    metric_function=accuracy,\n    epochs=5,\n)","metadata":{"scrolled":true,"cellId":"jm7ckrss9ujmre2n6gfuc"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"cellId":"l6iocbrlhhi8i3yzt16k"},"outputs":[],"execution_count":null}]}