{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8df2951",
   "metadata": {},
   "outputs": [],
   "source": [
    "%env CUDA_VISIBLE_DEVICES=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf3c835",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl\n",
    "from pl_bolts.optimizers.lr_scheduler import LinearWarmupCosineAnnealingLR\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchmetrics import Accuracy\n",
    "from torchvision.models import mobilenet_v2\n",
    "from pathlib import Path\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from tutorial_utils.dataset import create_imagenette_dataloaders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1df4368",
   "metadata": {},
   "source": [
    "# Train baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6ea2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LitModel(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = mobilenet_v2(pretrained=False, num_classes=10)\n",
    "        self.metric = Accuracy()\n",
    "        \n",
    "        HOME_DIR = Path('./')\n",
    "        DATASETS_DIR = HOME_DIR / 'datasets'\n",
    "        PROJECT_DIR = HOME_DIR / 'lightning_mobilenet_pruning'\n",
    "        \n",
    "        HOME_DIR.mkdir(exist_ok=True)\n",
    "        DATASETS_DIR.mkdir(exist_ok=True)\n",
    "        PROJECT_DIR.mkdir(exist_ok=True)\n",
    "        \n",
    "        self.dataloaders = create_imagenette_dataloaders(\n",
    "            dataset_root_dir=DATASETS_DIR, \n",
    "            project_dir=PROJECT_DIR,\n",
    "            input_size=(224, 224),\n",
    "            batch_size=64,\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.RAdam(self.parameters(), lr=1e-2)\n",
    "        self.optimizer = optimizer\n",
    "        steps_per_epoch = len(self.train_dataloader())\n",
    "        scheduler = LinearWarmupCosineAnnealingLR(\n",
    "            optimizer,\n",
    "            warmup_epochs=50 * steps_per_epoch,\n",
    "            max_epochs=500 * steps_per_epoch,\n",
    "        )\n",
    "        self.scheduler = scheduler\n",
    "        \n",
    "        return {\n",
    "            'optimizer': optimizer,\n",
    "            'lr_scheduler': {\n",
    "                'scheduler': scheduler,\n",
    "                'interval': 'step',\n",
    "                'frequency': 1,\n",
    "            }\n",
    "        }\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        images, labels = batch\n",
    "        pred = self(images)\n",
    "        loss = F.cross_entropy(pred, labels)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        images, labels = batch\n",
    "        pred = self(images)\n",
    "        pred_labels = torch.argmax(pred, dim=1)\n",
    "        val_loss = F.cross_entropy(pred, labels)\n",
    "        self.log(\"val_loss\", val_loss)\n",
    "        self.log(\"val batch accuracy\", self.metric(pred_labels, labels), on_epoch=True)\n",
    "        \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        images, labels = batch\n",
    "        pred = self(images)\n",
    "        pred_labels = torch.argmax(pred, dim=1)\n",
    "        test_loss = F.cross_entropy(pred, labels)\n",
    "        self.log(\"test_loss\", test_loss)\n",
    "        self.log(\"val batch accuracy\", self.metric(pred_labels, labels), on_epoch=True)\n",
    "        \n",
    "    def validation_epoch_end(self, validation_step_outputs):\n",
    "        if hasattr(self, 'optimizer'):\n",
    "            self.log(\"lr\", self.optimizer.param_groups[0]['lr'])        \n",
    "        self.log(\"val epoch accuracy\", self.metric.compute())\n",
    "        \n",
    "    def test_epoch_end(self, validation_step_outputs):\n",
    "        if hasattr(self, 'optimizer'):\n",
    "            self.log(\"lr\", self.optimizer.param_groups[0]['lr'])        \n",
    "        self.log(\"val epoch accuracy\", self.metric.compute())\n",
    "        \n",
    "    def train_dataloader(self):\n",
    "        return self.dataloaders['tune_train_dataloader']\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return self.dataloaders['tune_validation_dataloader']\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return self.dataloaders['tune_validation_dataloader']\n",
    "\n",
    "    def predict_dataloader(self):\n",
    "        return self.dataloaders['tune_validation_dataloader']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741a0b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LitModel()\n",
    "trainer = pl.Trainer(max_epochs=500, accelerator='gpu', devices=1)\n",
    "trainer.fit(model=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e040ce97",
   "metadata": {},
   "source": [
    "# For pruning we need to accumulate gradients on prunable model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6453e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enot.pruning import EnotPruningCalibrator\n",
    "from enot.pruning import prune_model\n",
    "from enot.pruning import get_labels_for_equal_pruning\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38614a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "pruning_ratio = 0.45  # This gives about x3 FLOPs reduction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0674f9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "lit_model = LitModel()\n",
    "# Load pretrained weights with 93.27% accuracy. If you train model from scratch - load your checkpoint\n",
    "# model_state = torch.load('lightning_logs/version_0/checkpoints/epoch=499-step=59000.ckpt')['state_dict']\n",
    "# lit_model.load_state_dict(model_state)\n",
    "lit_model.cuda();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6fe591",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = pl.Trainer(accelerator='gpu', devices=1)\n",
    "trainer.test(lit_model, dataloaders=lit_model.test_dataloader())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355d3c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "lit_model.cuda();\n",
    "pruning_calibrator = EnotPruningCalibrator(model=lit_model)\n",
    "with pruning_calibrator:\n",
    "    for batch_idx, batch in enumerate(lit_model.train_dataloader()):\n",
    "        loss = lit_model.training_step(batch, batch_idx)\n",
    "        loss.backward()\n",
    "\n",
    "pruning_info = pruning_calibrator.pruning_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1757e593",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_channel_indices_to_prune = get_labels_for_equal_pruning(pruning_info, pruning_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dca645f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pruned_model = prune_model(\n",
    "    model=lit_model,\n",
    "    pruning_info=pruning_info,\n",
    "    prune_labels=all_channel_indices_to_prune,\n",
    "    inplace=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76567496",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(pruned_model.model, 'pruned_model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a771e0",
   "metadata": {},
   "source": [
    "# Finetune pruned model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dccd554",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TuneLitModel(LitModel):\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.RAdam(self.parameters(), lr=1e-3)\n",
    "        self.optimizer = optimizer\n",
    "        steps_per_epoch = len(self.train_dataloader())\n",
    "        scheduler = LinearWarmupCosineAnnealingLR(\n",
    "            optimizer,\n",
    "            warmup_epochs=15 * steps_per_epoch,\n",
    "            max_epochs=150 * steps_per_epoch,\n",
    "        )\n",
    "        self.scheduler = scheduler\n",
    "        \n",
    "        return {\n",
    "            'optimizer': optimizer,\n",
    "            'lr_scheduler': {\n",
    "                'scheduler': scheduler,\n",
    "                'interval': 'step',\n",
    "                'frequency': 1,\n",
    "            }\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299f961d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pruned_model = TuneLitModel()\n",
    "pruned_model.model = torch.load('pruned_model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28debd80",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = pl.Trainer(max_epochs=150, accelerator='gpu', devices=1)\n",
    "trainer.fit(model=pruned_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f7340e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.test(model=pruned_model, dataloaders=pruned_model.test_dataloader())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d7892c",
   "metadata": {},
   "source": [
    "# Measure latency difference in FLOPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8e4f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enot.latency import MacCalculatorPthflops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1782e1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "lit_model.cpu()\n",
    "MacCalculatorPthflops().calculate(lit_model.model, torch.ones((1,3,224,224)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee2476a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pruned_model.cpu()\n",
    "MacCalculatorPthflops().calculate(pruned_model.model, torch.ones((1,3,224,224)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b36d969",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mindtrace",
   "language": "python",
   "name": "mindtrace"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
