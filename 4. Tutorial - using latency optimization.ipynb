{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using latency optimization with custom operations\n",
    "\n",
    "This notebook describes the additional steps required to enable latency optimization for custom models.\n",
    "\n",
    "### Main chapters of this notebook:\n",
    "1. Setup the environment\n",
    "1. Prepare dataset and create dataloaders\n",
    "1. Adding custom modules (head/stem/custom_operation) with latency to use them in search space\n",
    "1. Build model with custom operations\n",
    "1. Check pretrain, search and tune phases\n",
    "    1. Pretrain search space\n",
    "    1. Search without latency loss\n",
    "    1. Search with latency loss\n",
    "    1. Tune found architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup the environment\n",
    "\n",
    "First, let's set up the environment and make some common imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'\n",
    "# You may need to uncomment and change this variable to match free GPU index\n",
    "#os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.optim import SGD\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch_optimizer import RAdam\n",
    "\n",
    "from pkg_resources import parse_version, get_distribution\n",
    "\n",
    "if parse_version(get_distribution('torchvision').version) < parse_version('0.9'):\n",
    "    from torchvision.models.mobilenet import ConvBNReLU\n",
    "else:\n",
    "    from torchvision.models.mobilenetv2 import ConvBNReLU\n",
    "\n",
    "from enot.models import SearchSpaceModel\n",
    "from enot.models.operations import SearchableMobileInvertedBottleneck\n",
    "from enot.models.operations import SearchVariantsContainer\n",
    "from enot.optimize import EnotPretrainOptimizer\n",
    "from enot.optimize import EnotSearchOptimizer\n",
    "from enot.latency import conv_mac_count\n",
    "from enot.latency import LatencyMixin\n",
    "from enot.latency import initialize_latency\n",
    "from enot.latency import best_arch_latency\n",
    "from enot.utils.common import input_hw\n",
    "\n",
    "from tutorial_utils.train import accuracy\n",
    "from tutorial_utils.train import WarmupScheduler\n",
    "\n",
    "from tutorial_utils.dataset import create_imagenette_dataloaders\n",
    "from tutorial_utils.phases import tutorial_pretrain_loop\n",
    "from tutorial_utils.phases import tutorial_search_loop\n",
    "from tutorial_utils.phases import tutorial_train_loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare dataset and create dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ENOT_HOME_DIR = Path.home() / '.enot'\n",
    "ENOT_DATASETS_DIR = ENOT_HOME_DIR / 'datasets'\n",
    "PROJECT_DIR = ENOT_HOME_DIR / 'using_latency_optimization'\n",
    "\n",
    "ENOT_HOME_DIR.mkdir(exist_ok=True)\n",
    "ENOT_DATASETS_DIR.mkdir(exist_ok=True)\n",
    "PROJECT_DIR.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = create_imagenette_dataloaders(\n",
    "    dataset_root_dir=ENOT_DATASETS_DIR, \n",
    "    project_dir=PROJECT_DIR,\n",
    "    input_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    imagenette_kind='imagenette2-320',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding custom modules (head/stem/custom_operation) with latency to use them in search space\n",
    "\n",
    "To add latency support for your module, you need to implement latency calculation.\n",
    "\n",
    "Adding latency calculation is done in two steps:\n",
    "1. Subclass your class from `enot.latency.LatencyMixin`. `LatencyMixin` is a part of latency calculation mechanism in `SearchSpaceModel`. By using this mixin, user can define methods of latency calculation for custom modules (see the next step).\n",
    "2. Add a method with a signature `latency_<name>(self, inputs) -> float`, which will calculate latency of each added operation.\n",
    "\n",
    "At this moment, only `'mmac'` (millions of multiply-accumulates) latency type is supported."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define custom operation with latency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyOperation(nn.Module, LatencyMixin):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels,\n",
    "        out_channels,\n",
    "        stride,\n",
    "        kernel_size=3,\n",
    "        padding=None,\n",
    "        use_skip_connection=True,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        if padding is None:\n",
    "            padding = (kernel_size - 1) // 2\n",
    "\n",
    "        self.stride = stride\n",
    "        self.kernel_size = kernel_size\n",
    "        self.padding = padding\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.use_skip_connection = use_skip_connection and in_channels == out_channels and stride == 1\n",
    "\n",
    "        self.operation = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels=in_channels,\n",
    "                out_channels=out_channels,\n",
    "                kernel_size=kernel_size,\n",
    "                stride=stride,\n",
    "                padding=padding,\n",
    "            ),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.operation(x)\n",
    "        if self.use_skip_connection:\n",
    "            out = out + x\n",
    "        return out\n",
    "\n",
    "    def latency_mmac(self, inputs):\n",
    "        \"\"\"Calculate number of millions of multiply-accumulate operations\"\"\"\n",
    "        spatial_size = input_hw(inputs)  # input_hw simply unpacks the spatial size of inputs\n",
    "        \n",
    "        def num_conv_steps(size, padding, kernel, stride):\n",
    "            size = size + 2 * padding - (kernel - 1)\n",
    "            return (size + stride - 1) // stride\n",
    "\n",
    "        h, w = spatial_size\n",
    "        h_steps = num_conv_steps(h, self.padding, self.kernel_size, self.stride)\n",
    "        w_steps = num_conv_steps(w, self.padding, self.kernel_size, self.stride)\n",
    "\n",
    "        mmac = h_steps * w_steps * self.kernel_size**2 * self.in_channels * self.out_channels\n",
    "        mmac /= 10 ** 6\n",
    "\n",
    "        return mmac"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define head and stem for your model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyStem(ConvBNReLU, LatencyMixin):\n",
    "    def __init__(\n",
    "            self,\n",
    "            in_channels,\n",
    "            out_channels,\n",
    "            kernel_size=3,\n",
    "            stride=1,\n",
    "            groups=1,\n",
    "            norm_layer=None,\n",
    "    ):\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.groups = groups\n",
    "\n",
    "        super().__init__(in_channels, out_channels, kernel_size, stride, groups, norm_layer)\n",
    "\n",
    "    def latency_mmac(self, inputs):\n",
    "        \"\"\"Calculate millions of multiply-accumulates\"\"\"\n",
    "        spatial_size = input_hw(inputs)  # input_hw simply unpacks the spatial size of inputs\n",
    "        mmac, _ = conv_mac_count(\n",
    "            spatial_size=spatial_size,\n",
    "            kernel_size=self.kernel_size,\n",
    "            stride=self.stride,\n",
    "            in_channels=self.in_channels,\n",
    "            padding=0,\n",
    "            out_channels=self.out_channels,\n",
    "            groups=self.groups,\n",
    "        )\n",
    "\n",
    "        return mmac\n",
    "\n",
    "\n",
    "class MyHead(nn.Sequential, LatencyMixin):\n",
    "    def __init__(\n",
    "        self, \n",
    "        in_channels,\n",
    "        hidden_channels,\n",
    "        num_classes,\n",
    "        dropout_rate=0.2,\n",
    "    ):\n",
    "        self.in_channels = in_channels\n",
    "        self.hidden_channels = hidden_channels\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        super().__init__(\n",
    "            ConvBNReLU(in_channels, hidden_channels, kernel_size=1),\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Flatten(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(hidden_channels, num_classes),\n",
    "        )\n",
    "\n",
    "    def latency_mmac(self, inputs):\n",
    "        \"\"\"Calculate millions of multiply-accumulates\"\"\"\n",
    "        spatial_size = input_hw(inputs)  # input_hw simply unpacks the spatial size of inputs\n",
    "        mmac, (h_out, w_out) = conv_mac_count(spatial_size, 1, 1, self.in_channels, 0, self.hidden_channels)\n",
    "        mmac += h_out * w_out * self.hidden_channels / 10 ** 6\n",
    "        mmac += self.hidden_channels * self.num_classes / 10 ** 6\n",
    "\n",
    "        return mmac"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build model with custom operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.stem = MyStem(\n",
    "            in_channels=3, \n",
    "            out_channels=16, \n",
    "            stride=2,\n",
    "        )\n",
    "        self.body = nn.ModuleList([\n",
    "            self.build_search_variants(16, 24, 2),\n",
    "            self.build_search_variants(24, 24, 1),\n",
    "            self.build_search_variants(24, 32, 2),\n",
    "            self.build_search_variants(32, 32, 1),\n",
    "            self.build_search_variants(32, 64, 2),\n",
    "            self.build_search_variants(64, 64, 1),\n",
    "            self.build_search_variants(64, 96, 1),\n",
    "            self.build_search_variants(96, 160, 2),\n",
    "            self.build_search_variants(160, 160, 1),\n",
    "            self.build_search_variants(160, 320, 1),\n",
    "        ])\n",
    "        self.head = MyHead(\n",
    "            in_channels=320,\n",
    "            hidden_channels=1280,\n",
    "            num_classes=10,\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def build_search_variants(in_channels, out_channels, stride):\n",
    "        return SearchVariantsContainer([\n",
    "            SearchableMobileInvertedBottleneck(\n",
    "                in_channels=in_channels,\n",
    "                out_channels=out_channels,\n",
    "                kernel_size=3,\n",
    "                stride=stride,\n",
    "                expand_ratio=6,\n",
    "            ),\n",
    "            SearchableMobileInvertedBottleneck(\n",
    "                in_channels=in_channels,\n",
    "                out_channels=out_channels,\n",
    "                kernel_size=5,\n",
    "                stride=stride,\n",
    "                expand_ratio=6,\n",
    "            ),\n",
    "            MyOperation(\n",
    "                in_channels=in_channels,\n",
    "                out_channels=out_channels,\n",
    "                kernel_size=7,\n",
    "                stride=stride,\n",
    "            ),\n",
    "        ])\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.stem(x)\n",
    "\n",
    "        for block in self.body:\n",
    "            x = block(x)\n",
    "\n",
    "        x = self.head(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyModel()\n",
    "\n",
    "# move model to search space\n",
    "search_space = SearchSpaceModel(model).cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check pretrain, search and tune phases\n",
    "\n",
    "Let's check that everything works.\n",
    "\n",
    "In this tutorial we use the same pretrain/search/train loops as in <span style=\"color:green;white-space:nowrap\">***1. Tutorial - getting started***</span>.\n",
    "\n",
    "**IMPORTANT**:<br>\n",
    "To turn on latency optimization, you must set `latency_loss_weight` (> 0) parameter for `tutorial_search_loop`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pretrain search space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "N_EPOCHS = 3\n",
    "N_WARMUP_EPOCHS = 1\n",
    "len_train = len(dataloaders['pretrain_train_dataloader'])\n",
    "\n",
    "optimizer = SGD(params=search_space.model_parameters(), lr=0.06, momentum=0.9, weight_decay=1e-4)\n",
    "enot_optimizer = EnotPretrainOptimizer(search_space=search_space, optimizer=optimizer)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=len_train*N_EPOCHS, eta_min=1e-8)\n",
    "scheduler = WarmupScheduler(scheduler, warmup_steps=len_train*N_WARMUP_EPOCHS)\n",
    "loss_function = nn.CrossEntropyLoss().cuda()\n",
    "\n",
    "tutorial_pretrain_loop(\n",
    "    epochs=N_EPOCHS,\n",
    "    search_space=search_space,\n",
    "    enot_optimizer=enot_optimizer,\n",
    "    metric_function=accuracy,\n",
    "    loss_function=loss_function,\n",
    "    train_loader=dataloaders['pretrain_train_dataloader'],\n",
    "    validation_loader=dataloaders['pretrain_validation_dataloader'],\n",
    "    scheduler=scheduler,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search without latency loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "optimizer = RAdam(search_space.architecture_parameters(), lr=0.01)\n",
    "enot_optimizer = EnotSearchOptimizer(search_space=search_space, optimizer=optimizer)\n",
    "# backup weights for next cell\n",
    "torch.save({'model': search_space.state_dict()}, PROJECT_DIR / 'search_space_backup.pth')\n",
    "\n",
    "tutorial_search_loop(\n",
    "    epochs=5,\n",
    "    search_space=search_space,\n",
    "    enot_optimizer=enot_optimizer,\n",
    "    metric_function=accuracy,\n",
    "    loss_function=loss_function,\n",
    "    train_loader=dataloaders['search_train_dataloader'],\n",
    "    validation_loader=dataloaders['search_validation_dataloader'],\n",
    "    latency_loss_weight=0,\n",
    "    latency_type=None,\n",
    "    scheduler=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space.sample_best_arch()\n",
    "search_space.eval()\n",
    "\n",
    "sample_batch, _ = next(iter(dataloaders['search_train_dataloader']))\n",
    "initialize_latency('mmac', search_space, (sample_batch, ))\n",
    "latency_0 = best_arch_latency(search_space)\n",
    "print('best architecture latency (latency_loss_weight == 0) =', latency_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search with latency loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# restore weights\n",
    "checkpoint_data = torch.load(PROJECT_DIR / 'search_space_backup.pth')\n",
    "search_space.load_state_dict(checkpoint_data['model'])\n",
    "\n",
    "optimizer = RAdam(search_space.architecture_parameters(), lr=0.01)\n",
    "enot_optimizer = EnotSearchOptimizer(search_space=search_space, optimizer=optimizer)\n",
    "\n",
    "tutorial_search_loop(\n",
    "    epochs=5,\n",
    "    search_space=search_space,\n",
    "    enot_optimizer=enot_optimizer,\n",
    "    metric_function=accuracy,\n",
    "    loss_function=loss_function,\n",
    "    train_loader=dataloaders['search_train_dataloader'],\n",
    "    validation_loader=dataloaders['search_validation_dataloader'],\n",
    "    latency_loss_weight=2e-3,\n",
    "    latency_type='mmac',\n",
    "    scheduler=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_space.sample_best_arch()\n",
    "search_space.eval()\n",
    "\n",
    "sample_batch, _ = next(iter(dataloaders['search_train_dataloader']))\n",
    "initialize_latency('mmac', search_space, (sample_batch, ))\n",
    "latency_1 = best_arch_latency(search_space)\n",
    "print('best architecture latency (latency_loss_weight > 0) =', latency_1)\n",
    "print('best architecture latency (latency_loss_weight == 0) =', latency_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We should get an architecture with lower latency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tune best architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get regular model with the best architecture\n",
    "best_model = search_space.get_network_with_best_arch().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = RAdam(best_model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "\n",
    "tutorial_train_loop(\n",
    "    epochs=5,\n",
    "    model=best_model,\n",
    "    optimizer=optimizer,\n",
    "    metric_function=accuracy,\n",
    "    loss_function=loss_function,\n",
    "    train_loader=dataloaders['tune_train_dataloader'],\n",
    "    validation_loader=dataloaders['tune_validation_dataloader'],\n",
    "    scheduler=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "execution": {
   "timeout": 3000
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
