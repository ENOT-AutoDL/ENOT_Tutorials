{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resolution search\n",
    "\n",
    "This notebook describes the basic steps you need to optimize an architecture with fixed latency and search the best input resolution using NAS framework.\n",
    "\n",
    "### Main chapters of this notebook:\n",
    "1. Setup the environment\n",
    "1. Prepare dataset and create dataloaders\n",
    "1. Create model and move it into search space\n",
    "1. Pretrain constructed search space on different resolutions\n",
    "1. Search the best architecture and resolution\n",
    "1. Tune model with the best architecture on the best resolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup the environment\n",
    "First, let's set up the environment and make some common imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['CUDA_DEVICE_ORDER'] = 'PCI_BUS_ID'\n",
    "# You may need to uncomment and change this variable to match free GPU index\n",
    "# os.environ['CUDA_VISIBLE_DEVICES'] = '0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('../')\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch.optim import SGD\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.optim import RAdam\n",
    "\n",
    "from enot.latency import current_latency\n",
    "from enot.models import SearchSpaceModel\n",
    "from enot.models.mobilenet import build_mobilenet\n",
    "from enot.optimize import FixedLatencySearchOptimizer\n",
    "from enot.optimize import PretrainOptimizer\n",
    "\n",
    "from enot.experimental.resolution_search import ConstantResolutionStrategy\n",
    "from enot.experimental.resolution_search import PretrainResolutionStrategy\n",
    "from enot.experimental.resolution_search import ResolutionSearcherWithFixedLatencyIterator\n",
    "\n",
    "from tutorial_utils.train import accuracy\n",
    "from tutorial_utils.train import WarmupScheduler\n",
    "\n",
    "from tutorial_utils.checkpoints import download_resolution_search_pretrain_checkpoint\n",
    "from tutorial_utils.dataset import create_imagenette_dataloaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In the following cell we setup all necessary dirs\n",
    "\n",
    "* `HOME_DIR` - experiments home directory\n",
    "* `DATASETS_DIR` - root directory for datasets (imagenette2, ...)\n",
    "* `PROJECT_DIR` - project directory to save training logs, checkpoints, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HOME_DIR = Path.home() / '.optimization_experiments'\n",
    "DATASETS_DIR = HOME_DIR / 'datasets'\n",
    "PROJECT_DIR = HOME_DIR / 'classification_resolution_search'\n",
    "\n",
    "HOME_DIR.mkdir(exist_ok=True)\n",
    "DATASETS_DIR.mkdir(exist_ok=True)\n",
    "PROJECT_DIR.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare dataset and create dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloaders = create_imagenette_dataloaders(\n",
    "    dataset_root_dir=DATASETS_DIR,\n",
    "    project_dir=PROJECT_DIR,\n",
    "    input_size=(224, 224),\n",
    "    batch_size=32,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create model and move it into search space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search space will have these ops as choose options in each layer.\n",
    "# Short format for operations is 'Name_param1=value1_param2=value2...'.\n",
    "# MIB is a MNv2 inverted bottleneck, k is a kernel size for depthwise\n",
    "# convolution, and t is an expansion ratio coefficient.\n",
    "# See more in-depth info in \"Tutorial - adding custom operations\".\n",
    "SEARCH_OPS = [\n",
    "    'MIB_k=3_t=6',\n",
    "    'MIB_k=5_t=6',\n",
    "    'MIB_k=7_t=6',\n",
    "    'conv1x1-skip',\n",
    "]\n",
    "\n",
    "# build model\n",
    "model = build_mobilenet(\n",
    "    search_ops=SEARCH_OPS,\n",
    "    num_classes=10,\n",
    "    blocks_out_channels=[24, 32, 64, 96, 160, 320],\n",
    "    blocks_count=[2, 2, 2, 1, 2, 1],\n",
    "    blocks_stride=[2, 2, 2, 1, 2, 1],\n",
    ")\n",
    "\n",
    "# move model to search space\n",
    "search_space = SearchSpaceModel(model).cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretrain constructed search space\n",
    "Pretrain phase in the case of resolution search is similar to the regular pretrain procedure. You can find the detailed description of the regular pretrain procedure in <span style=\"color:green;white-space:nowrap\">***1. Tutorial - getting started***</span>.\n",
    "\n",
    "These are the required extra steps for resolution search:\n",
    "1. Create `PretrainResolutionStrategy` iterator object.\n",
    "1. Wrap your train and validation dataloaders with this iterator to generate resized images.\n",
    "\n",
    "This makes your pretrain procedure resiliant to different resolution values.\n",
    "\n",
    "**IMPORTANT: `PretrainResolutionStrategy.__call__(...)` returns an iterator, you must apply this strategy on every epoch to train_loader and validation_loader.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "N_EPOCHS = 3\n",
    "N_WARMUP_EPOCHS = 1\n",
    "\n",
    "# Create PretrainResolutionStrategy for resolution range [min_resolution, max_resolution].\n",
    "pretrain_resolution_strategy = PretrainResolutionStrategy(\n",
    "    min_resolution=100,\n",
    "    max_resolution=300,\n",
    ")\n",
    "\n",
    "constant_resolution_strategy = ConstantResolutionStrategy((300 + 100) // 2)\n",
    "\n",
    "train_loader = dataloaders['pretrain_train_dataloader']\n",
    "validation_loader = dataloaders['pretrain_validation_dataloader']\n",
    "\n",
    "metric_function = accuracy\n",
    "loss_function = nn.CrossEntropyLoss().cuda()\n",
    "\n",
    "# Using `search_space.model_parameters()` as optimizable variables.\n",
    "optimizer = SGD(params=search_space.model_parameters(), lr=0.06, momentum=0.9, weight_decay=1e-4)\n",
    "pretrain_optimizer = PretrainOptimizer(search_space=search_space, optimizer=optimizer)\n",
    "\n",
    "len_train_loader = len(train_loader)\n",
    "scheduler = CosineAnnealingLR(optimizer, T_max=len_train_loader * N_EPOCHS, eta_min=1e-8)\n",
    "scheduler = WarmupScheduler(scheduler, warmup_steps=len_train_loader * N_WARMUP_EPOCHS)\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    print(f'EPOCH #{epoch}')\n",
    "\n",
    "    search_space.train()\n",
    "    train_metrics_acc = {\n",
    "        'loss': 0.0,\n",
    "        'accuracy': 0.0,\n",
    "        'n': 0,\n",
    "    }\n",
    "    # apply resolution strategy and start iteration\n",
    "    for inputs, labels in pretrain_resolution_strategy(train_loader):\n",
    "        if not search_space.output_distribution_optimization_enabled:\n",
    "            search_space.initialize_output_distribution_optimization(inputs)\n",
    "\n",
    "        pretrain_optimizer.zero_grad()\n",
    "\n",
    "        def closure():\n",
    "            pred_labels = search_space(inputs)\n",
    "            batch_loss = loss_function(pred_labels, labels)\n",
    "            batch_loss.backward()\n",
    "            batch_metric = metric_function(pred_labels, labels)\n",
    "\n",
    "            train_metrics_acc['loss'] += batch_loss.item()\n",
    "            train_metrics_acc['accuracy'] += batch_metric.item()\n",
    "            train_metrics_acc['n'] += 1\n",
    "\n",
    "        pretrain_optimizer.step(closure)\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "\n",
    "    train_loss = train_metrics_acc['loss'] / train_metrics_acc['n']\n",
    "    train_accuracy = train_metrics_acc['accuracy'] / train_metrics_acc['n']\n",
    "\n",
    "    print('train metrics:')\n",
    "    print('  loss:', train_loss)\n",
    "    print('  accuracy:', train_accuracy)\n",
    "\n",
    "    arch_to_test = [0] * len(search_space.search_variants_containers)\n",
    "    test_model = search_space.get_network_by_indexes(arch_to_test)\n",
    "    test_model.eval()\n",
    "\n",
    "    validation_loss = 0\n",
    "    validation_accuracy = 0\n",
    "    with torch.no_grad():\n",
    "        # apply resolution strategy and start iteration\n",
    "        for inputs, labels in constant_resolution_strategy(validation_loader):\n",
    "            pred_labels = test_model(inputs)\n",
    "            batch_loss = loss_function(pred_labels, labels)\n",
    "            batch_metric = metric_function(pred_labels, labels)\n",
    "\n",
    "            validation_loss += batch_loss.item()\n",
    "            validation_accuracy += batch_metric.item()\n",
    "\n",
    "    n = len(validation_loader)\n",
    "    validation_loss /= n\n",
    "    validation_accuracy /= n\n",
    "\n",
    "    print('validation metrics:')\n",
    "    print('  loss:', validation_loss)\n",
    "    print('  accuracy:', validation_accuracy)\n",
    "\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We pretrained search space for 3 epochs in this example. In this cell, we are downloading\n",
    "# search space checkpoint, pretrained for 100 epochs (for demonstration purposes).\n",
    "\n",
    "checkpoint_path = PROJECT_DIR / 'resolution_search_pretrain_checkpoint.pth'\n",
    "download_resolution_search_pretrain_checkpoint(checkpoint_path)\n",
    "\n",
    "search_space.load_state_dict(\n",
    "    torch.load(checkpoint_path)['model'],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search the best architecture and resolution\n",
    "Search phase in case of resolution search is simular to regular pretrain procedure. You can find the detailed description of the regular search procedure in <span style=\"color:green;white-space:nowrap\">***1. Tutorial - getting started***</span>.\n",
    "\n",
    "These are the required extra steps for resolution search:\n",
    "1. Create `FixedLatencySearchOptimizer` instance as described in <span style=\"color:green;white-space:nowrap\">***6. Tutorial - search with the specified latency***</span>.\n",
    "1. Create `ResolutionSearcherWithFixedLatencyIterator` iterator object and provide latency search bounds.\n",
    "1. Iterate over `ResolutionSearcherWithFixedLatencyIterator` via `for` loop. This performs the following:\n",
    "    1. Iterator resets your search space states and initializes latency for the current resolution;\n",
    "    1. Resets your search optimizer state;\n",
    "    1. Returns (resolution, resolution_strategy) pair, where the first item is the resolution for the current search step, and the second is the transform which you should apply over your dataloaders.\n",
    "1. You must follow the regular search phase steps for each iteration over `ResolutionSearcherWithFixedLatencyIterator`.\n",
    "1. Before each next iteration, you should send your last validation target metric to `set_resolution_target_metric` function of `ResolutionSearcherWithFixedLatencyIterator`.\n",
    "\n",
    "**IMPORTANT: `resolution_strategy.__call__(...)` returns an iterator, you must apply this strategy on every epoch to train_loader and validation_loader.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This parameters are chosen for illustrative purposes.\n",
    "# Uncomment lines below to reach better performance of searched model.\n",
    "N_EPOCHS = 2\n",
    "WARMUP_STEPS = 1\n",
    "resolution_tolerance = 32\n",
    "\n",
    "# N_EPOCHS = 50\n",
    "# WARMUP_STEPS = 5\n",
    "# resolution_tolerance = 8\n",
    "\n",
    "target_latency = 100.0\n",
    "\n",
    "metric_function = accuracy\n",
    "loss_function = nn.CrossEntropyLoss().cuda()\n",
    "\n",
    "train_loader = dataloaders['search_train_dataloader']\n",
    "validation_loader = dataloaders['search_validation_dataloader']\n",
    "\n",
    "optimizer = RAdam(search_space.architecture_parameters(), lr=0.01)\n",
    "len_train_loader = len(train_loader)\n",
    "\n",
    "search_optimizer = FixedLatencySearchOptimizer(\n",
    "    search_space,\n",
    "    optimizer,\n",
    "    max_latency_value=target_latency,\n",
    ")\n",
    "\n",
    "# Create SearchResolutionWithFixedLatencyIterator object\n",
    "# for fixed resolution range and fixed target latency\n",
    "search_resolution_iter = ResolutionSearcherWithFixedLatencyIterator(\n",
    "    search_optimizer=search_optimizer,\n",
    "    dataloader=train_loader,\n",
    "    latency_type='mmac.fvcore',\n",
    "    min_resolution=100,\n",
    "    max_resolution=300,\n",
    "    resolution_tolerance=resolution_tolerance,\n",
    ")\n",
    "\n",
    "for r_step, (resolution, resolution_strategy) in enumerate(search_resolution_iter):\n",
    "    print(f'RESOLUTION_SEARCH_STEP #{r_step}')\n",
    "    print(f'CURRENT RESOLUTION: {resolution}')\n",
    "\n",
    "    # We should not re-create search optimizer as it's state is controlled by the resolution searcher.\n",
    "\n",
    "    # We should re-create scheduler as it is not updated by the resolution searcher.\n",
    "    scheduler = CosineAnnealingLR(optimizer, T_max=len_train_loader * N_EPOCHS, eta_min=1e-8)\n",
    "    scheduler = WarmupScheduler(scheduler, warmup_steps=len_train_loader * WARMUP_STEPS)\n",
    "\n",
    "    validation_accuracy, latency = None, None\n",
    "    for epoch in range(N_EPOCHS):\n",
    "        print(f'EPOCH #{epoch}')\n",
    "\n",
    "        search_space.train()\n",
    "        train_metrics_acc = {\n",
    "            'loss': 0.0,\n",
    "            'accuracy': 0.0,\n",
    "            'n': 0,\n",
    "        }\n",
    "        # Apply resolution strategy and iterate over samples.\n",
    "        for inputs, labels in resolution_strategy(train_loader):\n",
    "            search_optimizer.zero_grad()\n",
    "\n",
    "            def closure():\n",
    "                pred_labels = search_space(inputs)\n",
    "                batch_loss = loss_function(pred_labels, labels)\n",
    "                batch_loss = search_optimizer.modify_loss(batch_loss)\n",
    "\n",
    "                batch_loss.backward()\n",
    "                batch_metric = metric_function(pred_labels, labels)\n",
    "\n",
    "                train_metrics_acc['loss'] += batch_loss.item()\n",
    "                train_metrics_acc['accuracy'] += batch_metric.item()\n",
    "                train_metrics_acc['n'] += 1\n",
    "\n",
    "            search_optimizer.step(closure)\n",
    "            scheduler.step()\n",
    "\n",
    "        train_loss = train_metrics_acc['loss'] / train_metrics_acc['n']\n",
    "        train_accuracy = train_metrics_acc['accuracy'] / train_metrics_acc['n']\n",
    "\n",
    "    search_space.eval()\n",
    "    # prepare_validation_model function samples an optimal architecture\n",
    "    # in the search space and prepares it to the validation procedure.\n",
    "    search_optimizer.prepare_validation_model()\n",
    "\n",
    "    validation_loss = 0\n",
    "    validation_accuracy = 0\n",
    "    with torch.no_grad():\n",
    "        # Apply resolution strategy and iterate over samples.\n",
    "        for inputs, labels in resolution_strategy(validation_loader):\n",
    "            pred_labels = search_space(inputs)\n",
    "            batch_loss = loss_function(pred_labels, labels)\n",
    "            batch_metric = metric_function(pred_labels, labels)\n",
    "\n",
    "            validation_loss += batch_loss.item()\n",
    "            validation_accuracy += batch_metric.item()\n",
    "\n",
    "    n = len(validation_loader)\n",
    "    validation_loss /= n\n",
    "    validation_accuracy /= n\n",
    "\n",
    "    # Getting latency of the current sampled architecure.\n",
    "    # The current architecture is the best one (for this epoch)\n",
    "    # as it is sampled by prepare_validation_model function/\n",
    "    latency = current_latency(search_space)\n",
    "\n",
    "    print('train accuracy:', train_accuracy)\n",
    "    print('train loss:', train_loss)\n",
    "    print('validation accuracy:', validation_accuracy)\n",
    "    print('validation loss:', validation_loss)\n",
    "    print('latency:', latency)\n",
    "    print()\n",
    "\n",
    "    # Apply the obtained target metric (validation accuracy) to the resolution search object.\n",
    "    search_resolution_iter.set_resolution_target_metric(validation_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now our search space is initialized with the best state\n",
    "# (see ResolutionSearcherWithFixedLatencyIterator documentation).\n",
    "\n",
    "best_resolution = search_resolution_iter.best_resolution\n",
    "best_architecture = search_resolution_iter.best_architecture\n",
    "\n",
    "print(f'Best resolution is {best_resolution}')\n",
    "print(f'Best architecture is {best_architecture}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tune model with the best architecture\n",
    "Now we take our best architecture from search space, and create a regular model using it. Then we run finetune procedure (usual training loop)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get regular model with the best architecture\n",
    "best_model = search_space.get_network_by_indexes(best_architecture).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "N_EPOCHS = 5\n",
    "\n",
    "optimizer = SGD(best_model.parameters(), lr=2e-4, momentum=0.9, weight_decay=1e-4)\n",
    "scheduler = None\n",
    "metric_function = accuracy\n",
    "loss_function = nn.CrossEntropyLoss().cuda()\n",
    "\n",
    "train_loader = dataloaders['tune_train_dataloader']\n",
    "validation_loader = dataloaders['tune_validation_dataloader']\n",
    "\n",
    "# ConstantResolutionStrategy is a wrapper over your dataloader to produce images of fixed resolution.\n",
    "# You can use it to reproduce data processing pipeline from resolution search procedure.\n",
    "to_best_resolution = ConstantResolutionStrategy(resolution=best_resolution)\n",
    "\n",
    "for epoch in range(N_EPOCHS):\n",
    "    print(f'EPOCH #{epoch}')\n",
    "\n",
    "    best_model.train()\n",
    "    train_loss = 0.0\n",
    "    train_accuracy = 0.0\n",
    "    for inputs, labels in to_best_resolution(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        pred_labels = best_model(inputs)\n",
    "        batch_loss = loss_function(pred_labels, labels)\n",
    "        batch_loss.backward()\n",
    "        batch_metric = metric_function(pred_labels, labels)\n",
    "\n",
    "        train_loss += batch_loss.item()\n",
    "        train_accuracy += batch_metric.item()\n",
    "\n",
    "        optimizer.step()\n",
    "        if scheduler is not None:\n",
    "            scheduler.step()\n",
    "\n",
    "    n = len(train_loader)\n",
    "    train_loss /= n\n",
    "    train_accuracy /= n\n",
    "\n",
    "    print('train metrics:')\n",
    "    print('  loss:', train_loss)\n",
    "    print('  accuracy:', train_accuracy)\n",
    "\n",
    "    best_model.eval()\n",
    "    validation_loss = 0\n",
    "    validation_accuracy = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in to_best_resolution(validation_loader):\n",
    "            pred_labels = best_model(inputs)\n",
    "            batch_loss = loss_function(pred_labels, labels)\n",
    "            batch_metric = metric_function(pred_labels, labels)\n",
    "\n",
    "            validation_loss += batch_loss.item()\n",
    "            validation_accuracy += batch_metric.item()\n",
    "\n",
    "    n = len(validation_loader)\n",
    "    validation_loss /= n\n",
    "    validation_accuracy /= n\n",
    "\n",
    "    print('validation metrics:')\n",
    "    print('  loss:', validation_loss)\n",
    "    print('  accuracy:', validation_accuracy)\n",
    "\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "execution": {
   "timeout": 3000
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
